
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Warming-up &#8212; Deep Learning for Experimental Psychologists and Cognitive Neuroscientists</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=888ff710"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=36754332"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-BXYWD71FWS"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-BXYWD71FWS');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-BXYWD71FWS');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/assignments/warmup';</script>
    <link rel="icon" href="../../_static/icon.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Optimisation and Learning" href="optimisation_learning.html" />
    <link rel="prev" title="9. Reinforcement Learning" href="../reinforcement_learning.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt="Deep Learning for Experimental Psychologists and Cognitive Neuroscientists - Home"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt="Deep Learning for Experimental Psychologists and Cognitive Neuroscientists - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    Welcome
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Prerequisites</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../markdowns/environment_setup.html">0. Environment Setup</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../networks_building_blocks.html">1. Network’s Building Blocks</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../convolution.html">1.1. Convolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../activation_function.html">1.2. Activation Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pooling.html">1.3. Pooling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear.html">1.4. Linear Layer</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start.html">2. Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimisation_learning.html">3. Optimisation and Learning</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../vision.html">4. Vision</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../image_classification.html">4.1. Image Classification</a></li>





<li class="toctree-l2"><a class="reference internal" href="../image_segmentation.html">4.2. Image Segmentation</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../other_modalities.html">5. Other Modalities</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../audio_classification.html">5.1. Audio Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../text_classification.html">5.2. Text Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../clip.html">5.3. Language – Vision</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../generative_models.html">6. Deep Generative Models</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../gan.html">6.1. Generative Adversarial Network</a></li>






<li class="toctree-l2"><a class="reference internal" href="../vae.html">6.2. Deep Autoencoder</a></li>







<li class="toctree-l2"><a class="reference internal" href="../dpm.html">6.3. Diffusion Probabilistic Model</a></li>






<li class="toctree-l2"><a class="reference internal" href="../llm.html">6.4. Large Language Model</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../interpretation_techniques.html">7. Interpretation Techniques</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../activation.html">7.1. Activation Maps</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesion.html">7.2. Kernel Lesioning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_classifier_probe.html">7.3. Probing by linear classifiers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro-to-rsa.html">7.4. Introduction to Representational Similarity Analysis</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../big_projects.html">8. Big Projects</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../markdowns/python_scripting.html">8.1. Python Scripting</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensorboard.html">8.2. TensorBoard</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../markdowns/server.html">8.3. Working with Servers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../reinforcement_learning.html">9. Reinforcement Learning</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Assignments</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Warming-up</a></li>
<li class="toctree-l1"><a class="reference internal" href="optimisation_learning.html">Optimisation and Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="llm_assignment.html">LLM Calculator</a></li>
<li class="toctree-l1"><a class="reference internal" href="zeroshot_evaluation.html">Zero-shot Evaluation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Student Projects</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../student_projects/deep-learning-with-dobble.html">Deep Learning with Dobble</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Complementary Materials</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../python_course/beginners.html">Python For Beginners</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../python_course/dataTypes.html">Data Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python_course/modules.html">Modules and NumPy Arrays</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python_course/conditions.html">Conditions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python_course/loops.html">Loops</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python_course/plotting.html">Plotting</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python_course/functions.html">Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python_course/moduleObjects.html">Modules and Objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python_course/inheritance.html">Inheritance</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/DeepLearning-JupyterBook/deeplearning-jupyterbook.github.io/blob/master/notebooks/assignments/warmup.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/DeepLearning-JupyterBook/deeplearning-jupyterbook.github.io" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/DeepLearning-JupyterBook/deeplearning-jupyterbook.github.io/edit/master//notebooks/assignments/warmup.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/DeepLearning-JupyterBook/deeplearning-jupyterbook.github.io/issues/new?title=Issue%20on%20page%20%2Fnotebooks/assignments/warmup.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/notebooks/assignments/warmup.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Warming-up</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#working-with-resnet">Working with ResNet</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-s-parameters">Model’s Parameters</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#loading-an-image">Loading an Image</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#transforming-the-image-into-a-tensor">Transforming the Image into a Tensor</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#running-the-model">Running the Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#assessing-the-output">Assessing the Output</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#assignment">Assignment</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualise-kernels-of-the-first-layer">1. Visualise Kernels of the First Layer</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#load-multiple-images">2. Load Multiple Images</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#explore-a-different-architecture">3. Explore a Different Architecture</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bonus-questions-optional">Bonus Questions (Optional)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#add-noise-to-the-first-layer">4. Add Noise to the First Layer</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#add-noise-to-the-input-image">5. Add Noise to the Input Image</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#convolve-with-a-single-kernel">6. Convolve with a Single Kernel</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#apply-an-activation-function">7. Apply an Activation Function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pooling-operation">8. Pooling Operation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-layer">9. Linear Layer</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="warming-up">
<h1>Warming-up<a class="headerlink" href="#warming-up" title="Link to this heading">#</a></h1>
<p>The purpose of this assignment is to help you become familiar with a pretrained network designed for object recognition on ImageNet. Specifically, we will explore the building blocks of this network, such as convolutional layers, activation functions, pooling, and linear layers, and understand how each layer contributes to the network’s functionality.</p>
<p>Let’s begin by importing all necessary packages for the assignment.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import required libraries</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span><span class="p">,</span> <span class="n">models</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">import</span> <span class="nn">skimage</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
</pre></div>
</div>
</div>
</div>
<section id="working-with-resnet">
<h2>Working with ResNet<a class="headerlink" href="#working-with-resnet" title="Link to this heading">#</a></h2>
<p>In this assignment, we’ll explore <strong>ResNet</strong>, <a class="reference external" href="https://arxiv.org/abs/1512.03385">a popular deep learning architecture</a> for image recognition. ResNet is known for its unique design, which helps it learn complex patterns in images. Here, we’ll use a pretrained ResNet18 model, which is trained on the large ImageNet dataset. By using a pretrained model, we can quickly experiment with a powerful network without needing to train it ourselves.</p>
<p>We can load the model with pretrained weights by specifying <code class="docutils literal notranslate"><span class="pre">weights=models.ResNet18_Weights.IMAGENET1K_V1</span></code>, which refers to weights trained on 1000 ImageNet classes. Since we don’t want to update these weights during testing, we set the model to evaluation mode using <code class="docutils literal notranslate"><span class="pre">.eval()</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load the pretrained ResNet18 model with ImageNet weights</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet18</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">models</span><span class="o">.</span><span class="n">ResNet18_Weights</span><span class="o">.</span><span class="n">IMAGENET1K_V1</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># Set model to evaluation mode, so weights are not updated</span>

<span class="c1"># Print the model’s architecture to understand its structure</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=512, out_features=1000, bias=True)
)
</pre></div>
</div>
</div>
</div>
</section>
<section id="model-s-parameters">
<h2>Model’s Parameters<a class="headerlink" href="#model-s-parameters" title="Link to this heading">#</a></h2>
<p>To understand what’s happening inside the network, let’s look at its parameters. Each layer has parameters, such as weights and biases, which are adjusted during training. We can check the names and shapes of these parameters to better understand how information flows through the network.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Loop through each parameter in the model</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
    <span class="c1"># Print the name and shape of each parameter</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">name</span><span class="si">:</span><span class="s1">&lt;28</span><span class="si">}</span><span class="s1"> </span><span class="se">\t</span><span class="s1"> </span><span class="si">{</span><span class="n">param</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>conv1.weight                 	 torch.Size([64, 3, 7, 7])
bn1.weight                   	 torch.Size([64])
bn1.bias                     	 torch.Size([64])
layer1.0.conv1.weight        	 torch.Size([64, 64, 3, 3])
layer1.0.bn1.weight          	 torch.Size([64])
layer1.0.bn1.bias            	 torch.Size([64])
layer1.0.conv2.weight        	 torch.Size([64, 64, 3, 3])
layer1.0.bn2.weight          	 torch.Size([64])
layer1.0.bn2.bias            	 torch.Size([64])
layer1.1.conv1.weight        	 torch.Size([64, 64, 3, 3])
layer1.1.bn1.weight          	 torch.Size([64])
layer1.1.bn1.bias            	 torch.Size([64])
layer1.1.conv2.weight        	 torch.Size([64, 64, 3, 3])
layer1.1.bn2.weight          	 torch.Size([64])
layer1.1.bn2.bias            	 torch.Size([64])
layer2.0.conv1.weight        	 torch.Size([128, 64, 3, 3])
layer2.0.bn1.weight          	 torch.Size([128])
layer2.0.bn1.bias            	 torch.Size([128])
layer2.0.conv2.weight        	 torch.Size([128, 128, 3, 3])
layer2.0.bn2.weight          	 torch.Size([128])
layer2.0.bn2.bias            	 torch.Size([128])
layer2.0.downsample.0.weight 	 torch.Size([128, 64, 1, 1])
layer2.0.downsample.1.weight 	 torch.Size([128])
layer2.0.downsample.1.bias   	 torch.Size([128])
layer2.1.conv1.weight        	 torch.Size([128, 128, 3, 3])
layer2.1.bn1.weight          	 torch.Size([128])
layer2.1.bn1.bias            	 torch.Size([128])
layer2.1.conv2.weight        	 torch.Size([128, 128, 3, 3])
layer2.1.bn2.weight          	 torch.Size([128])
layer2.1.bn2.bias            	 torch.Size([128])
layer3.0.conv1.weight        	 torch.Size([256, 128, 3, 3])
layer3.0.bn1.weight          	 torch.Size([256])
layer3.0.bn1.bias            	 torch.Size([256])
layer3.0.conv2.weight        	 torch.Size([256, 256, 3, 3])
layer3.0.bn2.weight          	 torch.Size([256])
layer3.0.bn2.bias            	 torch.Size([256])
layer3.0.downsample.0.weight 	 torch.Size([256, 128, 1, 1])
layer3.0.downsample.1.weight 	 torch.Size([256])
layer3.0.downsample.1.bias   	 torch.Size([256])
layer3.1.conv1.weight        	 torch.Size([256, 256, 3, 3])
layer3.1.bn1.weight          	 torch.Size([256])
layer3.1.bn1.bias            	 torch.Size([256])
layer3.1.conv2.weight        	 torch.Size([256, 256, 3, 3])
layer3.1.bn2.weight          	 torch.Size([256])
layer3.1.bn2.bias            	 torch.Size([256])
layer4.0.conv1.weight        	 torch.Size([512, 256, 3, 3])
layer4.0.bn1.weight          	 torch.Size([512])
layer4.0.bn1.bias            	 torch.Size([512])
layer4.0.conv2.weight        	 torch.Size([512, 512, 3, 3])
layer4.0.bn2.weight          	 torch.Size([512])
layer4.0.bn2.bias            	 torch.Size([512])
layer4.0.downsample.0.weight 	 torch.Size([512, 256, 1, 1])
layer4.0.downsample.1.weight 	 torch.Size([512])
layer4.0.downsample.1.bias   	 torch.Size([512])
layer4.1.conv1.weight        	 torch.Size([512, 512, 3, 3])
layer4.1.bn1.weight          	 torch.Size([512])
layer4.1.bn1.bias            	 torch.Size([512])
layer4.1.conv2.weight        	 torch.Size([512, 512, 3, 3])
layer4.1.bn2.weight          	 torch.Size([512])
layer4.1.bn2.bias            	 torch.Size([512])
fc.weight                    	 torch.Size([1000, 512])
fc.bias                      	 torch.Size([1000])
</pre></div>
</div>
</div>
</div>
<p>Each line in the output represents a layer in ResNet, showing:</p>
<ul class="simple">
<li><p><strong>Layer Name</strong>: Identifies the layer (e.g., <code class="docutils literal notranslate"><span class="pre">conv1.weight</span></code> refers to the weights in the first convolutional layer).</p></li>
<li><p><strong>Shape</strong>: The dimensions of each parameter tensor, which indicates how data is transformed as it passes through the model.</p></li>
</ul>
<p>This information can help you understand the model’s structure and the size of data transformations at each stag</p>
</section>
<section id="loading-an-image">
<h2>Loading an Image<a class="headerlink" href="#loading-an-image" title="Link to this heading">#</a></h2>
<p>Let’s download an example image from a URL and display its content. Note that PyTorch expects images in the PIL format by default, but similar functions can be implemented using NumPy if preferred.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Download an example image</span>
<span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://github.com/pytorch/hub/raw/master/images/dog.jpg&quot;</span>
<span class="n">input_image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">skimage</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">url</span><span class="p">))</span>  <span class="c1"># Load and convert to PIL format</span>

<span class="c1"># Resize and display the image for easy viewing</span>
<span class="n">input_image</span> <span class="o">=</span> <span class="n">input_image</span><span class="o">.</span><span class="n">resize</span><span class="p">((</span><span class="n">input_image</span><span class="o">.</span><span class="n">width</span> <span class="o">//</span> <span class="mi">5</span><span class="p">,</span> <span class="n">input_image</span><span class="o">.</span><span class="n">height</span> <span class="o">//</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">input_image</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/39aa64c5be63a4a02a47a4a6a40a3b119c7a201cca9990130a68163cfe2c92ea.png" src="../../_images/39aa64c5be63a4a02a47a4a6a40a3b119c7a201cca9990130a68163cfe2c92ea.png" />
</div>
</div>
</section>
<section id="transforming-the-image-into-a-tensor">
<h2>Transforming the Image into a Tensor<a class="headerlink" href="#transforming-the-image-into-a-tensor" title="Link to this heading">#</a></h2>
<p>Pretrained models expect input images in a specific format:</p>
<ul class="simple">
<li><p>Images are typically mini-batches of 3-channel RGB images with shape <code class="docutils literal notranslate"><span class="pre">(3</span> <span class="pre">x</span> <span class="pre">H</span> <span class="pre">x</span> <span class="pre">W)</span></code>, where <code class="docutils literal notranslate"><span class="pre">H</span></code> and <code class="docutils literal notranslate"><span class="pre">W</span></code> should be at least 224.</p></li>
<li><p>The image values should be in the range <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">1]</span></code>, then normalised with <code class="docutils literal notranslate"><span class="pre">mean</span> <span class="pre">=</span> <span class="pre">[0.485,</span> <span class="pre">0.456,</span> <span class="pre">0.406]</span></code> and <code class="docutils literal notranslate"><span class="pre">std</span> <span class="pre">=</span> <span class="pre">[0.229,</span> <span class="pre">0.224,</span> <span class="pre">0.225]</span></code>.</p></li>
</ul>
<p>Here’s a sample transformation:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define preprocessing steps</span>
<span class="n">preprocess</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">]),</span>
<span class="p">])</span>

<span class="c1"># Apply preprocessing and create a mini-batch</span>
<span class="n">input_tensor</span> <span class="o">=</span> <span class="n">preprocess</span><span class="p">(</span><span class="n">input_image</span><span class="p">)</span>
<span class="n">input_batch</span> <span class="o">=</span> <span class="n">input_tensor</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Create a batch dimension</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="running-the-model">
<h2>Running the Model<a class="headerlink" href="#running-the-model" title="Link to this heading">#</a></h2>
<p>In evaluation mode, we use <code class="docutils literal notranslate"><span class="pre">with</span> <span class="pre">torch.no_grad()</span></code> to prevent the computation of gradients, making processing more efficient as we won’t need backpropagation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Move to GPU if available for faster computation</span>
<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">input_batch</span> <span class="o">=</span> <span class="n">input_batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>

<span class="c1"># Run the model in evaluation mode</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_batch</span><span class="p">)</span>

<span class="c1"># Output size should match the 1000 ImageNet classes</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="s2">&quot;Output size:&quot;</span><span class="si">:</span><span class="s1">&lt;20</span><span class="si">}</span><span class="s1"> </span><span class="se">\t</span><span class="s1"> </span><span class="si">{</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="c1"># Convert output scores to probabilities using softmax</span>
<span class="n">probabilities</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="s2">&quot;Probabilities size:&quot;</span><span class="si">:</span><span class="s1">&lt;20</span><span class="si">}</span><span class="s1"> </span><span class="se">\t</span><span class="s1"> </span><span class="si">{</span><span class="n">probabilities</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Output size:         	 torch.Size([1, 1000])
Probabilities size:  	 torch.Size([1000])
</pre></div>
</div>
</div>
</div>
</section>
<section id="assessing-the-output">
<h2>Assessing the Output<a class="headerlink" href="#assessing-the-output" title="Link to this heading">#</a></h2>
<p>To interpret the model’s output, we need the labels corresponding to the 1000 ImageNet classes. We’ll retrieve these labels online.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Download ImageNet labels</span>
<span class="kn">import</span> <span class="nn">requests</span>

<span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt&#39;</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="n">imagenet_classes</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">splitlines</span><span class="p">()</span>  <span class="c1"># Convert the text to a list</span>

<span class="c1"># Verify the labels list</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">imagenet_classes</span><span class="p">))</span>  <span class="c1"># Should be 1000</span>
<span class="nb">print</span><span class="p">(</span><span class="n">imagenet_classes</span><span class="p">[:</span><span class="mi">10</span><span class="p">])</span>  <span class="c1"># Show the first 10 classes</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1000
[&#39;tench&#39;, &#39;goldfish&#39;, &#39;great white shark&#39;, &#39;tiger shark&#39;, &#39;hammerhead&#39;, &#39;electric ray&#39;, &#39;stingray&#39;, &#39;cock&#39;, &#39;hen&#39;, &#39;ostrich&#39;]
</pre></div>
</div>
</div>
</div>
<p>Now, let’s display the top 5 predicted categories for our image.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get the top 5 categories</span>
<span class="n">top5_prob</span><span class="p">,</span> <span class="n">top5_catid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">probabilities</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">top5_prob</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">imagenet_classes</span><span class="p">[</span><span class="n">top5_catid</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span><span class="si">:</span><span class="s1">&lt;17</span><span class="si">}</span><span class="s1"> </span><span class="si">{</span><span class="n">top5_prob</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Samoyed           0.859
Arctic fox        0.055
white wolf        0.049
Pomeranian        0.008
Great Pyrenees    0.007
</pre></div>
</div>
</div>
</div>
</section>
<hr class="docutils" />
<section id="assignment">
<h2>Assignment<a class="headerlink" href="#assignment" title="Link to this heading">#</a></h2>
<p>For this assignment, please address the following tasks. Submit your responses in a single <strong>notebook (.ipynb)</strong> that includes code, comments, written text, and plots. Ensure that the notebook is self-contained and can be run on other machines.</p>
<section id="visualise-kernels-of-the-first-layer">
<h3>1. Visualise Kernels of the First Layer<a class="headerlink" href="#visualise-kernels-of-the-first-layer" title="Link to this heading">#</a></h3>
<p>Access the weights of the first layer using <code class="docutils literal notranslate"><span class="pre">conv1.weight</span></code>, which has a shape of <code class="docutils literal notranslate"><span class="pre">torch.Size([64,</span> <span class="pre">3,</span> <span class="pre">7,</span> <span class="pre">7])</span></code>. Your visualisation should display 64 colour kernels of size <span class="math notranslate nohighlight">\(7 \times 7\)</span>.</p>
</section>
<section id="load-multiple-images">
<h3>2. Load Multiple Images<a class="headerlink" href="#load-multiple-images" title="Link to this heading">#</a></h3>
<p>Modify <code class="docutils literal notranslate"><span class="pre">input_batch</span></code> to load 4 different images, run the model on all 4 simultaneously, and display the predicted classes for each image.</p>
</section>
<section id="explore-a-different-architecture">
<h3>3. Explore a Different Architecture<a class="headerlink" href="#explore-a-different-architecture" title="Link to this heading">#</a></h3>
<p>Visualise the first-layer kernels of a different network such as AlexNet (<code class="docutils literal notranslate"><span class="pre">models.alexnet</span></code>), VGG (<code class="docutils literal notranslate"><span class="pre">models.vgg16</span></code>), or ViT-B16 (<code class="docutils literal notranslate"><span class="pre">models.vit_b_16</span></code>). Compare these kernels with what you know about the receptive fields in the mammalian visual cortex. Discuss any similarities and differences.</p>
</section>
</section>
<hr class="docutils" />
<section id="bonus-questions-optional">
<h2>Bonus Questions (Optional)<a class="headerlink" href="#bonus-questions-optional" title="Link to this heading">#</a></h2>
<p>These questions will provide extra points.</p>
<section id="add-noise-to-the-first-layer">
<h3>4. Add Noise to the First Layer<a class="headerlink" href="#add-noise-to-the-first-layer" title="Link to this heading">#</a></h3>
<p>Add a type of noise (e.g., Gaussian or Poisson) to the weights of the first layer (<code class="docutils literal notranslate"><span class="pre">conv1.weight</span></code> or <code class="docutils literal notranslate"><span class="pre">conv1.bias</span></code>). Evaluate how sensitive the network is to this noise.</p>
</section>
<section id="add-noise-to-the-input-image">
<h3>5. Add Noise to the Input Image<a class="headerlink" href="#add-noise-to-the-input-image" title="Link to this heading">#</a></h3>
<p>Add noise to the input images and observe how the network’s predictions are affected.</p>
</section>
<section id="convolve-with-a-single-kernel">
<h3>6. Convolve with a Single Kernel<a class="headerlink" href="#convolve-with-a-single-kernel" title="Link to this heading">#</a></h3>
<p>Convolve the input image with the first kernel in the first layer and visualise the resulting output.</p>
</section>
<section id="apply-an-activation-function">
<h3>7. Apply an Activation Function<a class="headerlink" href="#apply-an-activation-function" title="Link to this heading">#</a></h3>
<p>Apply an activation function, like ReLU, to the output of the convolution in the previous step.</p>
</section>
<section id="pooling-operation">
<h3>8. Pooling Operation<a class="headerlink" href="#pooling-operation" title="Link to this heading">#</a></h3>
<p>Apply a pooling function (e.g., max pooling with a <span class="math notranslate nohighlight">\(2 \times 2\)</span> window) to the convolution output from the previous step.</p>
</section>
<section id="linear-layer">
<h3>9. Linear Layer<a class="headerlink" href="#linear-layer" title="Link to this heading">#</a></h3>
<p>Apply a linear layer with an output node size of 1000 to the convolution output from the previous steps.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./notebooks/assignments"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../reinforcement_learning.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">9. Reinforcement Learning</p>
      </div>
    </a>
    <a class="right-next"
       href="optimisation_learning.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Optimisation and Learning</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#working-with-resnet">Working with ResNet</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-s-parameters">Model’s Parameters</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#loading-an-image">Loading an Image</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#transforming-the-image-into-a-tensor">Transforming the Image into a Tensor</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#running-the-model">Running the Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#assessing-the-output">Assessing the Output</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#assignment">Assignment</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualise-kernels-of-the-first-layer">1. Visualise Kernels of the First Layer</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#load-multiple-images">2. Load Multiple Images</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#explore-a-different-architecture">3. Explore a Different Architecture</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bonus-questions-optional">Bonus Questions (Optional)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#add-noise-to-the-first-layer">4. Add Noise to the First Layer</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#add-noise-to-the-input-image">5. Add Noise to the Input Image</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#convolve-with-a-single-kernel">6. Convolve with a Single Kernel</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#apply-an-activation-function">7. Apply an Activation Function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pooling-operation">8. Pooling Operation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-layer">9. Linear Layer</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Arash Akbarinia
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>