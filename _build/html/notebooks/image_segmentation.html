
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>4.2. Image Segmentation &#8212; Deep Learning for Experimental Psychologists and Cognitive Neuroscientists</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=36754332"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-BXYWD71FWS"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-BXYWD71FWS');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-BXYWD71FWS');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/image_segmentation';</script>
    <link rel="icon" href="../_static/icon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="4.3. Transfer Learning" href="transfer_learning.html" />
    <link rel="prev" title="4.1. Image Classification" href="image_classification.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Deep Learning for Experimental Psychologists and Cognitive Neuroscientists - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Deep Learning for Experimental Psychologists and Cognitive Neuroscientists - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Welcome
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Prerequisites</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../markdowns/environment_setup.html">0. Environment Setup</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="networks_building_blocks.html">1. Network’s Building Blocks</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="convolution.html">1.1. Convolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="activation_function.html">1.2. Activation Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="pooling.html">1.3. Pooling</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear.html">1.4. Linear Layer</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="quick_start.html">2. Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="optimisation_learning.html">3. Optimisation and Learning</a></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="vision.html">4. Vision</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="image_classification.html">4.1. Image Classification</a></li>





<li class="toctree-l2 current active"><a class="current reference internal" href="#">4.2. Image Segmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="transfer_learning.html">4.3. Transfer Learning</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="other_modalities.html">5. Other Modalities</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="audio_classification.html">5.1. Audio Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="text_classification.html">5.2. Text Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="clip.html">5.3. Language – Vision</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="generative_models.html">6. Deep Generative Models</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="gan.html">6.1. Generative Adversarial Network</a></li>






<li class="toctree-l2"><a class="reference internal" href="vae.html">6.2. Deep Autoencoder</a></li>







<li class="toctree-l2"><a class="reference internal" href="dpm.html">6.3. Diffusion Probabilistic Model</a></li>






<li class="toctree-l2"><a class="reference internal" href="llm.html">6.4. Large Language Model</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="interpretation_techniques.html">7. Interpretation Techniques</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="activation.html">7.1. Activation Maps</a></li>
<li class="toctree-l2"><a class="reference internal" href="lesion.html">7.2. Kernel Lesioning</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_classifier_probe.html">7.3. Probing by linear classifiers</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro-to-rsa.html">7.4. Representational Similarity Analysis</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="big_projects.html">8. Big Projects</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../markdowns/python_scripting.html">8.1. Python Scripting</a></li>
<li class="toctree-l2"><a class="reference internal" href="tensorboard.html">8.2. TensorBoard</a></li>
<li class="toctree-l2"><a class="reference internal" href="../markdowns/server.html">8.3. Working with Servers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="reinforcement_learning.html">9. Reinforcement Learning</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Assignments</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="assignments/warmup.html">Warming-up</a></li>
<li class="toctree-l1"><a class="reference internal" href="assignments/optimisation_learning.html">Optimisation and Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="assignments/llm_assignment.html">LLM Calculator</a></li>
<li class="toctree-l1"><a class="reference internal" href="assignments/zeroshot_evaluation.html">Zero-shot Evaluation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Student Projects</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="student_projects/deep-learning-with-dobble.html">Deep Learning with Dobble</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Complementary Materials</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="python_course/beginners.html">Python For Beginners</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="python_course/dataTypes.html">Data Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="python_course/modules.html">Modules and NumPy Arrays</a></li>
<li class="toctree-l2"><a class="reference internal" href="python_course/conditions.html">Conditions</a></li>
<li class="toctree-l2"><a class="reference internal" href="python_course/loops.html">Loops</a></li>
<li class="toctree-l2"><a class="reference internal" href="python_course/plotting.html">Plotting</a></li>
<li class="toctree-l2"><a class="reference internal" href="python_course/functions.html">Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="python_course/moduleObjects.html">Modules and Objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="python_course/inheritance.html">Inheritance</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/DeepLearning-JupyterBook/deeplearning-jupyterbook.github.io/blob/master/notebooks/image_segmentation.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/DeepLearning-JupyterBook/deeplearning-jupyterbook.github.io" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/DeepLearning-JupyterBook/deeplearning-jupyterbook.github.io/edit/master//notebooks/image_segmentation.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/DeepLearning-JupyterBook/deeplearning-jupyterbook.github.io/issues/new?title=Issue%20on%20page%20%2Fnotebooks/image_segmentation.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/notebooks/image_segmentation.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>4.2. Image Segmentation</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preparation">0. Preparation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#required-packages">Required Packages</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset">1. Dataset</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-utility-functions">Dataset Utility Functions</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-backgrounds">Creating Backgrounds</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#drawing-foreground-shapes">Drawing Foreground Shapes</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-tiled-images">Creating Tiled Images</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#visualising-the-dataset">Visualising the Dataset</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch-data-pipeline">PyTorch Data Pipeline</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#data-augmentation">Data Augmentation</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#data-transformations">Data Transformations</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#dataloader-managing-data-batches">DataLoader: Managing Data Batches</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model">2. Model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#architecture">Architecture</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#image-classification">Image Classification</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#semantic-segmentation">Semantic Segmentation</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#network">Network</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-and-testing-routines">3. Training and Testing Routines</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optimiser">Optimiser</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#loss-function">Loss Function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-utility-functions">Training utility functions</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#experiments-with-uniform-background">4. Experiments with Uniform Background</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#actual-learning">Actual Learning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#reporting-results">Reporting Results</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualising-the-model-s-output">Visualising the Model’s Output</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#experiment-with-noise">5. Experiment With Noise</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Reporting Results</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Visualising the Model’s Output</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">6. Exercises</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="image-segmentation">
<h1>4.2. Image Segmentation<a class="headerlink" href="#image-segmentation" title="Link to this heading">#</a></h1>
<p>In this notebook, we expand on the <a class="reference internal" href="quick_start.html"><span class="std std-doc">geometrical shape classification project</span></a> we studied earlier. Previously, the network’s output was a <strong>single label for the entire image</strong>, indicating the category of the overall image.</p>
<p>Here, we will extend this to predict a <strong>label for each pixel</strong> in the image, identifying the category each pixel belongs to. This type of problem is called <strong>semantic segmentation</strong>. Semantic segmentation is widely used in fields such as medical imaging (e.g., tumour detection) and autonomous driving (e.g., identifying roads, pedestrians, and vehicles).</p>
<p>To adapt the classification task to semantic segmentation, we need to make the following changes:</p>
<ol class="arabic simple">
<li><p><strong>Dataset</strong>:</p>
<ul class="simple">
<li><p>Instead of a single label per image, we now require <strong>ground truth</strong> for each pixel.</p></li>
<li><p>The ground truth will consist of images where each pixel is assigned a category label.</p></li>
</ul>
</li>
<li><p><strong>Network Architecture</strong>:</p>
<ul class="simple">
<li><p>The network must output a <strong>matrix</strong> with the same spatial resolution as the input image (height × width).</p></li>
<li><p>Each pixel in the output matrix corresponds to a predicted category for the corresponding input pixel.</p></li>
</ul>
</li>
</ol>
<section id="preparation">
<h2>0. Preparation<a class="headerlink" href="#preparation" title="Link to this heading">#</a></h2>
<p>Before we dive into the project, let’s start by preparing the necessary materials.</p>
<section id="required-packages">
<h3>Required Packages<a class="headerlink" href="#required-packages" title="Link to this heading">#</a></h3>
<p>Let’s start with all the necessary packages to implement this tutorial.</p>
<ul class="simple">
<li><p><strong><a class="reference external" href="https://numpy.org/">numpy</a>:</strong> The main library for scientific computing in Python, commonly imported as <code class="docutils literal notranslate"><span class="pre">np</span></code>.</p></li>
<li><p><strong><a class="reference external" href="https://matplotlib.org/">matplotlib</a>:</strong> Useful for plotting graphs and visualising data.</p></li>
<li><p><strong><a class="reference external" href="https://pytorch.org/docs/stable/index.html">torch</a>:</strong> The core library in PyTorch for deep learning, helping us define and manage neural networks.</p></li>
<li><p><strong><a class="reference external" href="https://pytorch.org/vision/stable/index.html">torchvision</a>:</strong> Contains tools and datasets for computer vision tasks.</p></li>
<li><p><strong><a class="reference external" href="https://docs.opencv.org/4.x/index.html">cv2</a> (OpenCV):</strong> A widely-used library for image processing.</p></li>
</ul>
<p>Let’s import these libraries now:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># importing the necessary packages/libraries</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torchvision</span>

<span class="kn">import</span> <span class="nn">cv2</span>
</pre></div>
</div>
</div>
</div>
<p>Deep learning tasks can be computationally demanding. GPUs are often used because they are designed to handle complex calculations efficiently. In this case, if a <strong>GPU</strong> is available, PyTorch will use it; otherwise, it will default to using the <strong>CPU</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Automatically selects GPU if available, else defaults to CPU</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="dataset">
<h2>1. Dataset<a class="headerlink" href="#dataset" title="Link to this heading">#</a></h2>
<p>In this section, we prepare our dataset for semantic segmentation. Instead of using pre-existing data, we will <strong>generate our dataset on the fly</strong>. This is useful for teaching purposes and allows us to focus on specific features of the task.</p>
<p>Our dataset consists of images containing simple geometrical shapes:</p>
<ul class="simple">
<li><p><strong>Circle</strong></p></li>
<li><p><strong>Ellipse</strong></p></li>
<li><p><strong>Rectangle</strong></p></li>
</ul>
<p>Each image is paired with a <strong>segmentation mask</strong>, where every pixel is labelled as:</p>
<ul class="simple">
<li><p><strong>0 (background)</strong></p></li>
<li><p><strong>1 (circle)</strong></p></li>
<li><p><strong>2 (ellipse)</strong></p></li>
<li><p><strong>3 (rectangle)</strong></p></li>
</ul>
<p>We will also assign colours to these labels for visualisation purposes:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Mapping of labels to shape names</span>
<span class="n">label_to_shape</span> <span class="o">=</span> <span class="p">{</span>
    <span class="mi">0</span><span class="p">:</span> <span class="s1">&#39;background&#39;</span><span class="p">,</span>
    <span class="mi">1</span><span class="p">:</span> <span class="s1">&#39;circle&#39;</span><span class="p">,</span>
    <span class="mi">2</span><span class="p">:</span> <span class="s1">&#39;ellipse&#39;</span><span class="p">,</span>
    <span class="mi">3</span><span class="p">:</span> <span class="s1">&#39;rectangle&#39;</span>
<span class="p">}</span>

<span class="c1"># Colours for visualisation (RGB values)</span>
<span class="n">label_colours</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;background&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>      <span class="c1"># Black</span>
    <span class="s1">&#39;circle&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>       <span class="c1"># Red</span>
    <span class="s1">&#39;ellipse&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>      <span class="c1"># Green</span>
    <span class="s1">&#39;rectangle&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">]</span>     <span class="c1"># Blue</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<section id="dataset-utility-functions">
<h3>Dataset Utility Functions<a class="headerlink" href="#dataset-utility-functions" title="Link to this heading">#</a></h3>
<p>We use utility functions to generate random backgrounds, draw shapes, and create segmentation masks.</p>
<section id="creating-backgrounds">
<h4>Creating Backgrounds<a class="headerlink" href="#creating-backgrounds" title="Link to this heading">#</a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">create_random_background</span></code> function generates backgrounds for the images. Backgrounds can either be:</p>
<ul class="simple">
<li><p><strong>Noisy</strong> (random pixel values) or</p></li>
<li><p><strong>Uniform</strong> (a single random colour).</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">create_random_background</span><span class="p">(</span><span class="n">img_size</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Creates a background for an image. </span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        img_size (int): Size of the background (image will be square).</span>
<span class="sd">        p (float): Probability of generating a random noise background.</span>
<span class="sd">        </span>
<span class="sd">    Returns:</span>
<span class="sd">        numpy array: Background image of size (img_size, img_size, 3).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># If a randomly generated number is above p, create a noise background; otherwise, use a uniform colour</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">&gt;</span> <span class="n">p</span><span class="p">:</span>
        <span class="c1"># Random noise background: random pixel values for each RGB channel</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="p">(</span><span class="n">img_size</span><span class="p">,</span> <span class="n">img_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;uint8&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Uniform background: same colour for each pixel</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">img_size</span><span class="p">,</span> <span class="n">img_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;uint8&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;uint8&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="drawing-foreground-shapes">
<h4>Drawing Foreground Shapes<a class="headerlink" href="#drawing-foreground-shapes" title="Link to this heading">#</a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">create_random_shape</span></code> function draws a random geometrical shape (circle, ellipse, or rectangle) on top of a background. It also creates the corresponding <strong>ground truth mask</strong>, where:</p>
<ul class="simple">
<li><p>The background is labelled as <strong>0</strong>, and</p></li>
<li><p>Each shape is assigned a unique label (1 for circle, 2 for ellipse, 3 for rectangle).</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">create_random_shape</span><span class="p">(</span><span class="n">background_img</span><span class="p">,</span> <span class="n">is_filled</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Draws a random geometrical shape on an image and creates a corresponding ground truth mask.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        background_img (numpy.ndarray): The background image.</span>
<span class="sd">        is_filled (bool): Whether the shapes should be filled or outlined.</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">        tuple: (image with shapes, ground truth mask)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Generate a random colour for the shape</span>
    <span class="n">shape_colour</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)]</span>
    
    <span class="c1"># Generate ground truth mask (single-channel image)</span>
    <span class="n">ground_truth</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">background_img</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
    
    <span class="c1"># Randomly choose a shape type (1: Circle, 2: Ellipse, 3: Rectangle)</span>
    <span class="n">shape_type</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">label_to_shape</span><span class="p">))</span>
    
    <span class="c1"># Randomly position and size the shape</span>
    <span class="n">centre</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">background_img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span> <span class="o">*</span> <span class="p">(</span><span class="n">background_img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="mi">4</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">shape_type</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># Circle</span>
        <span class="n">radius</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">background_img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="mi">4</span><span class="p">)</span>
        <span class="n">background_img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">circle</span><span class="p">(</span><span class="n">background_img</span><span class="p">,</span> <span class="n">centre</span><span class="p">,</span> <span class="n">radius</span><span class="p">,</span> <span class="n">shape_colour</span><span class="p">,</span> <span class="n">thickness</span><span class="o">=-</span><span class="mi">1</span> <span class="k">if</span> <span class="n">is_filled</span> <span class="k">else</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">ground_truth</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">circle</span><span class="p">(</span><span class="n">ground_truth</span><span class="p">,</span> <span class="n">centre</span><span class="p">,</span> <span class="n">radius</span><span class="p">,</span> <span class="n">shape_type</span><span class="p">,</span> <span class="n">thickness</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="k">elif</span> <span class="n">shape_type</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>  <span class="c1"># Ellipse</span>
        <span class="n">axes</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">)]</span>
        <span class="n">angle</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">360</span><span class="p">)</span>
        <span class="n">background_img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">ellipse</span><span class="p">(</span><span class="n">background_img</span><span class="p">,</span> <span class="n">centre</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">angle</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">360</span><span class="p">,</span> <span class="n">shape_colour</span><span class="p">,</span> <span class="n">thickness</span><span class="o">=-</span><span class="mi">1</span> <span class="k">if</span> <span class="n">is_filled</span> <span class="k">else</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">ground_truth</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">ellipse</span><span class="p">(</span><span class="n">ground_truth</span><span class="p">,</span> <span class="n">centre</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">angle</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">360</span><span class="p">,</span> <span class="n">shape_type</span><span class="p">,</span> <span class="n">thickness</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="k">elif</span> <span class="n">shape_type</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>  <span class="c1"># Rectangle</span>
        <span class="n">corner</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">background_img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">background_img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">rectangle</span><span class="p">(</span><span class="n">background_img</span><span class="p">,</span> <span class="n">centre</span><span class="p">,</span> <span class="n">corner</span><span class="p">,</span> <span class="n">shape_colour</span><span class="p">,</span> <span class="n">thickness</span><span class="o">=-</span><span class="mi">1</span> <span class="k">if</span> <span class="n">is_filled</span> <span class="k">else</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">ground_truth</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">rectangle</span><span class="p">(</span><span class="n">ground_truth</span><span class="p">,</span> <span class="n">centre</span><span class="p">,</span> <span class="n">corner</span><span class="p">,</span> <span class="n">shape_type</span><span class="p">,</span> <span class="n">thickness</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">background_img</span><span class="p">,</span> <span class="n">ground_truth</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="creating-tiled-images">
<h4>Creating Tiled Images<a class="headerlink" href="#creating-tiled-images" title="Link to this heading">#</a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">tile_image</span></code> function divides the image into tiles and adds a shape to each tile. This ensures multiple shapes appear in one image.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">tile_image</span><span class="p">(</span><span class="n">background_img</span><span class="p">,</span> <span class="n">is_filled</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Divides the background image into tiles and draws a shape in each tile.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        background_img (numpy.ndarray): Background image.</span>
<span class="sd">        is_filled (bool): Whether shapes are filled or outlined.</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">        tuple: (image with tiled shapes, ground truth mask)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">background_img</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">ground_truth</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
    
    <span class="n">num_tiles</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># Number of tiles along each dimension</span>
    <span class="n">tile_height</span> <span class="o">=</span> <span class="n">height</span> <span class="o">//</span> <span class="n">num_tiles</span>
    <span class="n">tile_width</span> <span class="o">=</span> <span class="n">width</span> <span class="o">//</span> <span class="n">num_tiles</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">tile_height</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">tile_width</span><span class="p">):</span>
            <span class="n">tile</span> <span class="o">=</span> <span class="n">background_img</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">tile_height</span><span class="p">,</span> <span class="n">j</span><span class="p">:</span><span class="n">j</span> <span class="o">+</span> <span class="n">tile_width</span><span class="p">]</span>
            <span class="n">tile_with_shape</span><span class="p">,</span> <span class="n">tile_mask</span> <span class="o">=</span> <span class="n">create_random_shape</span><span class="p">(</span><span class="n">tile</span><span class="p">,</span> <span class="n">is_filled</span><span class="p">)</span>
            <span class="n">background_img</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">tile_height</span><span class="p">,</span> <span class="n">j</span><span class="p">:</span><span class="n">j</span> <span class="o">+</span> <span class="n">tile_width</span><span class="p">]</span> <span class="o">=</span> <span class="n">tile_with_shape</span>
            <span class="n">ground_truth</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">tile_height</span><span class="p">,</span> <span class="n">j</span><span class="p">:</span><span class="n">j</span> <span class="o">+</span> <span class="n">tile_width</span><span class="p">]</span> <span class="o">=</span> <span class="n">tile_mask</span>
    
    <span class="k">return</span> <span class="n">background_img</span><span class="p">,</span> <span class="n">ground_truth</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="visualising-the-dataset">
<h4>Visualising the Dataset<a class="headerlink" href="#visualising-the-dataset" title="Link to this heading">#</a></h4>
<p>To make it easier to interpret the segmentation results, we can visualise all pixels belonging to the same category with the same colour. For instance, all rectangles will appear in blue, regardless of their surface colour. This standardised colouring helps to clearly distinguish between different object categories and makes it easier to evaluate the model’s performance visually.</p>
<p>To achieve this, we implement the <code class="docutils literal notranslate"><span class="pre">label_to_colour</span></code> function. This function iterates through all the labels in the image and assigns each one a predefined colour from a colour map.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">label_to_colour</span><span class="p">(</span><span class="n">mask</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Converts a label mask to a coloured image for visualisation.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        mask (numpy.ndarray): Ground truth mask.</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">        numpy.ndarray: Coloured representation of the mask.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">coloured_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="o">*</span><span class="n">mask</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">mask</span><span class="p">):</span>
        <span class="n">coloured_mask</span><span class="p">[</span><span class="n">mask</span> <span class="o">==</span> <span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">label_colours</span><span class="p">[</span><span class="n">label_to_shape</span><span class="p">[</span><span class="n">label</span><span class="p">]]</span>
    <span class="k">return</span> <span class="n">coloured_mask</span>
</pre></div>
</div>
</div>
</div>
<p>To better understand the generated data, we visualise pairs of:</p>
<ul class="simple">
<li><p><strong>Input images</strong> with random backgrounds and shapes that may have random colours for shapes and backgrounds.</p></li>
<li><p><strong>Ground truth masks</strong> use fixed colours for visualisation (e.g., blue for rectangles) but are stored as label numbers internally (0 for background, 1–3 for shapes).</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate and display 25 random examples</span>
<span class="n">img_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">is_filled</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">probability_noise</span> <span class="o">=</span> <span class="mf">0.5</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">25</span><span class="p">):</span>
    <span class="n">img</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="n">tile_image</span><span class="p">(</span><span class="n">create_random_background</span><span class="p">(</span><span class="n">img_size</span><span class="p">,</span> <span class="n">probability_noise</span><span class="p">),</span> <span class="n">is_filled</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span> <span class="o">//</span> <span class="mi">5</span><span class="p">,</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">5</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">img</span><span class="p">,</span> <span class="n">label_to_colour</span><span class="p">(</span><span class="n">mask</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span> <span class="o">//</span> <span class="mi">5</span><span class="p">,</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">5</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/f13247d91d4defb99d1740138aa1ce9352036fcdb305b2f81f8284498b85f73a.png" src="../_images/f13247d91d4defb99d1740138aa1ce9352036fcdb305b2f81f8284498b85f73a.png" />
</div>
</div>
</section>
</section>
<section id="pytorch-data-pipeline">
<h3>PyTorch Data Pipeline<a class="headerlink" href="#pytorch-data-pipeline" title="Link to this heading">#</a></h3>
<p>Now that we have created our dataset, we need to create <strong>PyTorch dataloaders</strong> to efficiently manage and load our data during model training and evaluation. PyTorch dataloaders make it easier to handle large datasets by loading small batches of data sequentially, which is essential for efficient memory usage and faster processing.</p>
<p>In PyTorch, the dataset class defines how to access and process individual data samples. To create a custom dataset, we inherit from <code class="docutils literal notranslate"><span class="pre">torch.utils.data.Dataset</span></code> and implement two mandatory methods:</p>
<ol class="arabic simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">__len__</span></code>:</strong> Returns the total number of samples in the dataset.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">__getitem__</span></code>:</strong> Returns a single sample (input image and corresponding label) when given an index.</p></li>
</ol>
<p>We have implemented the <code class="docutils literal notranslate"><span class="pre">ShapeDataset</span></code> class, which is responsible for generating data samples dynamically. This class uses the <code class="docutils literal notranslate"><span class="pre">tile_img</span></code> function within its <code class="docutils literal notranslate"><span class="pre">__getitem__</span></code> method to create a random sample whenever it is accessed.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Custom PyTorch Dataset for Shape Images</span>
<span class="k">class</span> <span class="nc">ShapeDataset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="n">img_size</span><span class="p">,</span> <span class="n">bg_type_probability</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialise the dataset with the necessary parameters.</span>

<span class="sd">        Args:</span>
<span class="sd">            num_samples (int): Number of samples in the dataset.</span>
<span class="sd">            img_size (int): Size of the images (assumes square images).</span>
<span class="sd">            bg_type_probability (float): Probability of a uniform vs noisy background.</span>
<span class="sd">            transform (callable, optional): Transformations to apply to input images.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span> <span class="o">=</span> <span class="n">num_samples</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">img_size</span> <span class="o">=</span> <span class="n">img_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bg_type_probability</span> <span class="o">=</span> <span class="n">bg_type_probability</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the total number of samples.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generate a single data sample.</span>

<span class="sd">        Args:</span>
<span class="sd">            index (int): Sample index (not used here since samples are generated randomly).</span>

<span class="sd">        Returns:</span>
<span class="sd">            tuple: (input_image, ground_truth) where</span>
<span class="sd">                   input_image is a tensor of shape [C, H, W],</span>
<span class="sd">                   ground_truth is a tensor of shape [H, W].</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Generate a random image and its ground truth</span>
        <span class="n">image</span><span class="p">,</span> <span class="n">ground_truth</span> <span class="o">=</span> <span class="n">tile_image</span><span class="p">(</span>
            <span class="n">create_random_background</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">img_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bg_type_probability</span><span class="p">),</span> <span class="n">is_filled</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>

        <span class="c1"># Apply transformations to the input image</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">:</span>
            <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

        <span class="c1"># Convert the ground truth to a PyTorch tensor (with long dtype for loss computation)</span>
        <span class="n">ground_truth</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">ground_truth</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">image</span><span class="p">,</span> <span class="n">ground_truth</span>
</pre></div>
</div>
</div>
</div>
<section id="data-augmentation">
<h4>Data Augmentation<a class="headerlink" href="#data-augmentation" title="Link to this heading">#</a></h4>
<p>In our <code class="docutils literal notranslate"><span class="pre">ShapeDataset</span></code>, the <code class="docutils literal notranslate"><span class="pre">transform</span></code> function is applied <strong>only to the input images</strong>. This is because the transformations we are using—normalisation and conversion to <code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code>—are relevant solely to the input data. The ground truth (labels) is converted to a PyTorch tensor separately without any additional transformations.</p>
<p>If we were to include image augmentations (e.g., cropping or random cropping) as part of the <code class="docutils literal notranslate"><span class="pre">transform</span></code> pipeline, <strong>we would need to apply the exact same augmentations to the ground truth</strong>. This ensures that the ground truth aligns with the modified input data. For example:</p>
<ul class="simple">
<li><p>If an image is randomly cropped, the corresponding label (e.g., segmentation mask) must also be cropped in the same way.</p></li>
<li><p>If an image is flipped horizontally, the label must also be flipped to maintain consistency.</p></li>
</ul>
<p>Failure to do this would lead to a <strong>mismatch</strong> between the input data and its corresponding labels, causing errors during training.</p>
<p>In most deep learning projects, data augmentation is a crucial step to prevent overfitting. Overfitting occurs when a model memorises the training set instead of learning generalisable patterns. Since neural networks often have millions of parameters, they can overfit when the training dataset is small or lacks diversity.</p>
<p>Random data augmentation introduces variability to the training samples, improving generalisation by:</p>
<ul class="simple">
<li><p>Simulating a broader range of input scenarios.</p></li>
<li><p>Forcing the network to learn robust features instead of relying on specific patterns in the dataset.</p></li>
</ul>
<p>In this example, we generate the data samples programmatically, and each sample is already randomised. As a result, our dataset inherently contains sufficient variability, eliminating the need for additional augmentations.</p>
</section>
<section id="data-transformations">
<h4>Data Transformations<a class="headerlink" href="#data-transformations" title="Link to this heading">#</a></h4>
<p>In this example, we use two standard transformations:</p>
<ol class="arabic simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">ToTensor</span></code></strong>: Converts an image into a PyTorch tensor. PyTorch models work with tensors, so we must apply this transformation before feeding data into our model.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">Normalize</span></code></strong>: Scales image pixel values so they are centred around zero. This is important because many deep learning models perform better when the data has a mean of zero and a standard deviation close to one. We specify the <code class="docutils literal notranslate"><span class="pre">mean</span></code> and <code class="docutils literal notranslate"><span class="pre">std</span></code> values for normalisation, tailored to our dataset.</p></li>
</ol>
<p>Transformations are applied sequentially using <code class="docutils literal notranslate"><span class="pre">torchvision.transforms.Compose</span></code>, which allows chaining multiple transformations together.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set mean and standard deviation for normalisation</span>
<span class="n">mean</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">std</span> <span class="o">=</span> <span class="mf">0.25</span>

<span class="c1"># Compose transformations</span>
<span class="n">transform</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>               <span class="c1"># Convert to tensor</span>
    <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">),</span>     <span class="c1"># Normalise with mean and std</span>
<span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="dataloader-managing-data-batches">
<h4>DataLoader: Managing Data Batches<a class="headerlink" href="#dataloader-managing-data-batches" title="Link to this heading">#</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> in PyTorch enables efficient batch processing, which is crucial for training and evaluation. Here are some important parameters for <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code>:</p>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">batch_size</span></code></strong>: Defines how many samples are processed in each batch. Processing in batches allows efficient use of GPU resources and is necessary for stochastic gradient descent (SGD).</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">num_workers</span></code></strong>: Specifies the number of CPU threads to load and preprocess the data before sending it to the GPU. Using multiple workers can speed up data loading, especially with larger datasets.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">shuffle</span></code></strong>: Randomly shuffles the data at each epoch. This is usually set to <code class="docutils literal notranslate"><span class="pre">True</span></code> during training to prevent the model from learning the order of the data.</p></li>
</ul>
<blockquote>
<div><p><strong>Note</strong>: <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> and <code class="docutils literal notranslate"><span class="pre">shuffle</span></code> settings can vary between training and testing. For example, we may set a larger <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> and avoid shuffling during testing since we do not need to update model weights.</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bg_type_probability</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># don&#39;t put noise in the background</span>

<span class="n">num_train_samples</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="c1"># Instantiate dataset for training</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">ShapeDataset</span><span class="p">(</span><span class="n">num_train_samples</span><span class="p">,</span> <span class="n">img_size</span><span class="p">,</span> <span class="n">bg_type_probability</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>

<span class="c1"># Set batch size</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">8</span>

<span class="c1"># Create DataLoader for training</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>

<span class="n">num_test_samples</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="c1"># Instantiate dataset for validation</span>
<span class="n">val_dataset</span> <span class="o">=</span> <span class="n">ShapeDataset</span><span class="p">(</span><span class="n">num_test_samples</span><span class="p">,</span> <span class="n">img_size</span><span class="p">,</span> <span class="n">bg_type_probability</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>

<span class="c1"># Create DataLoader for validation</span>
<span class="n">val_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">val_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="model">
<h2>2. Model<a class="headerlink" href="#model" title="Link to this heading">#</a></h2>
<p>With our images generated and PyTorch dataloaders ready, we can now move on to building our neural network model.</p>
<p>Since our task is relatively straightforward, we don’t need a highly complex model. In this example, we define a simple convolutional neural network (CNN) that will perform well on basic image classification tasks. Our model will inherit from <code class="docutils literal notranslate"><span class="pre">torch.nn.Module</span></code>, a base class in PyTorch used for creating neural network models. Any model that inherits from this class must implement at least a <code class="docutils literal notranslate"><span class="pre">forward</span></code> function, which defines how data will pass through the network layers.</p>
<section id="architecture">
<h3>Architecture<a class="headerlink" href="#architecture" title="Link to this heading">#</a></h3>
<p>Let’s revisit the architecture we used for image classification to understand the changes needed for semantic segmentation.</p>
<section id="image-classification">
<h4>Image Classification<a class="headerlink" href="#image-classification" title="Link to this heading">#</a></h4>
<p>For image classification, our network included:</p>
<ol class="arabic simple">
<li><p><strong>Feature Extraction</strong><br />
Gradually reduced the spatial resolution of the input while generating abstract feature sets to represent high-level concepts like shapes or textures.</p></li>
<li><p><strong>Global Average Pooling</strong><br />
Collapsed the spatial dimensions (height and width) by averaging across all locations. This produced a compact representation of the features, summarising the entire image.</p></li>
<li><p><strong>Classifier</strong><br />
A fully connected (linear) layer that mapped the summarised features to the number of classes, producing a single prediction for the entire image.</p></li>
</ol>
<p>In this setup, the final output was not spatially structured, as the goal was to predict a single label for the entire input image.</p>
</section>
<section id="semantic-segmentation">
<h4>Semantic Segmentation<a class="headerlink" href="#semantic-segmentation" title="Link to this heading">#</a></h4>
<p>For semantic segmentation, our objective changes: <strong>we need to predict a label for each pixel in the input image.</strong> This means the architecture must:</p>
<ol class="arabic simple">
<li><p>Extract meaningful features, as before.</p></li>
<li><p><strong>Upsample the spatial resolution</strong> of the extracted features to match the input image’s resolution.</p></li>
<li><p>Classify each pixel based on these upsampled features.</p></li>
</ol>
<p><strong>Key Modifications:</strong></p>
<ol class="arabic">
<li><p><strong>Upsampling the Features</strong><br />
Instead of global average pooling, we restore the spatial resolution using one or both of the following techniques:</p>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">torch.nn.functional.interpolate</span></code></strong><br />
This function performs interpolation to resize feature maps to the desired resolution. It is efficient and simple but does not involve any learnable parameters.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">torch.nn.ConvTranspose2d</span></code></strong><br />
Also known as transposed convolution, this operation upsamples feature maps using learnable weights, similar to standard convolutions but in reverse. It often produces sharper results compared to interpolation.</p></li>
</ul>
<p>In this example, we use a combination of both:</p>
<ul class="simple">
<li><p>Two <strong><code class="docutils literal notranslate"><span class="pre">ConvTranspose2d</span></code></strong> layers gradually upsample the features.</p></li>
<li><p>A final <strong><code class="docutils literal notranslate"><span class="pre">interpolate</span></code></strong> step ensures the output matches the exact resolution of the input image.</p></li>
</ul>
</li>
<li><p><strong>Pixel-Wise Classifier</strong><br />
Instead of a fully connected (linear) layer, we use a <strong>convolutional layer (<code class="docutils literal notranslate"><span class="pre">Conv2d</span></code>)</strong> with a kernel size of ( 1 \times 1 ). This allows the model to assign a class label to each pixel in the upsampled feature map.</p></li>
</ol>
<p>Recall from the image classification problem, our architecture contained three main components:</p>
<ol class="arabic simple">
<li><p><strong>Feature Extraction</strong>: Gradualyl reducing special resolution and create more abstract feature sets.</p></li>
<li><p><strong>Global Average Pooling</strong>: This layer pools the features across the entire spatial resolution, producing a summary of each feature map.</p></li>
<li><p><strong>Classifier</strong>: A linear layer maping the extracted features to the number of classes, providing the final predictions.</p></li>
</ol>
<p>This type of architecture, where all operations involve convolutional layers (including transposed convolutions), is known as a <strong>Fully Convolutional Network (FCN)</strong>. It was introduced in the seminal paper “<a class="reference external" href="https://arxiv.org/abs/1411.4038">Fully Convolutional Networks for Semantic Segmentation</a>”. FCNs form the foundation of modern semantic segmentation models.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the Simple CNN Model</span>
<span class="k">class</span> <span class="nc">SimpleNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># Feature extraction block (encoder)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="c1"># in=3, out=16</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">16</span><span class="p">),</span> <span class="c1"># it must be the same as out of prvious layer</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="c1"># in=16 (it must be the same as out of previous layer)</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">32</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">64</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="c1"># Upsampling block (decoder)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span> <span class="c1"># 64 comes from the output of the self.features</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">32</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">16</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="c1"># Classifier layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="c1"># Store the input size for final upsampling</span>
        <span class="n">size</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]</span>
        <span class="c1"># x shape is &lt;B, 3, 128, 128&gt;</span>
        
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># x shape is &lt;B, 64, 15, 15&gt;</span>
        
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># x shape is &lt;B, 16, 63, 63&gt;</span>
        
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">interpolate</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;bilinear&quot;</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="c1"># x shape is &lt;B, 16, 128, 128&gt;</span>
        
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># x shape is &lt;B, 4, 128, 128&gt;</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="network">
<h3>Network<a class="headerlink" href="#network" title="Link to this heading">#</a></h3>
<p>Next we make an instance of our previously defined architecture.
We move the model to GPU and print the model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the number of classes in the dataset (e.g., 4: background, circle, ellipse, rectangle)</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">label_to_shape</span><span class="p">)</span>

<span class="c1"># Create an instance of the SimpleNet model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SimpleNet</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">)</span>

<span class="c1"># Move the model to the GPU (if available)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Print the model architecture for reference</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>SimpleNet(
  (features): Sequential(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU(inplace=True)
    (7): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU(inplace=True)
    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (decoder): Sequential(
    (0): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2))
    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
  )
  (classifier): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1))
)
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="training-and-testing-routines">
<h2>3. Training and Testing Routines<a class="headerlink" href="#training-and-testing-routines" title="Link to this heading">#</a></h2>
<p>Now that we’ve prepared our dataset and built our model, it’s time to start training and evaluating our neural network. This section explains each component of the training process, including optimisation, loss calculation, and accuracy evaluation.</p>
<section id="optimiser">
<h3>Optimiser<a class="headerlink" href="#optimiser" title="Link to this heading">#</a></h3>
<p>The optimiser is responsible for updating the model’s parameters to minimise the loss during training. When defining an optimiser, we choose which parameters to optimise, the optimisation algorithm, and a key parameter called the <strong>learning rate</strong>. The learning rate controls how much to adjust the model’s parameters with each step.</p>
<p>In our case, we use <strong>Stochastic Gradient Descent (SGD)</strong> with parameters for <code class="docutils literal notranslate"><span class="pre">momentum</span></code>, <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code>, and <code class="docutils literal notranslate"><span class="pre">weight_decay</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define optimiser and criterion</span>
<span class="n">params_to_optimise</span> <span class="o">=</span> <span class="p">[{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()]}]</span>
<span class="n">momentum</span> <span class="o">=</span> <span class="mf">0.9</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">weight_decay</span> <span class="o">=</span> <span class="mf">1e-4</span>

<span class="c1"># Initialising the SGD optimiser with specified parameters</span>
<span class="n">optimiser</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span>
    <span class="n">params</span><span class="o">=</span><span class="n">params_to_optimise</span><span class="p">,</span>
    <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
    <span class="n">momentum</span><span class="o">=</span><span class="n">momentum</span><span class="p">,</span>
    <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="loss-function">
<h3>Loss Function<a class="headerlink" href="#loss-function" title="Link to this heading">#</a></h3>
<p>The <strong>loss function</strong> quantifies how well the model’s predictions match the ground truth. In this example, we use <strong>categorical cross-entropy</strong> (<code class="docutils literal notranslate"><span class="pre">nn.CrossEntropyLoss</span></code>) as our loss function, which is well-suited for classification tasks where the goal is to correctly categorise inputs into discrete classes (like recognising different shapes).</p>
<p>We can consider the learning paradigm in this example to be <strong>semi-supervised</strong>. The ground-truth labels for our shapes were not manually annotated by humans. Instead, we automatically generated these labels using mathematical equations to define the geometrical shapes. This approach allowed us to skip the laborious process of manually labelling each image, providing labelled data in a more efficient way.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Initialise the loss function (categorical cross-entropy)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="training-utility-functions">
<h3>Training utility functions<a class="headerlink" href="#training-utility-functions" title="Link to this heading">#</a></h3>
<p>For training semantic segmentation models, it is often helpful to define utility functions for monitoring performance and handling specific training nuances. Here, we define an <strong>accuracy</strong> function to evaluate how well the model’s predictions align with the ground truth.</p>
<p>In many scenarios, including ours, the background pixels can dominate the accuracy metric because they usually outnumber foreground pixels. Ignoring background pixels during accuracy computation allows us to focus on the model’s ability to segment the foreground objects. Here’s why this approach can be beneficial:</p>
<ol class="arabic simple">
<li><p><strong>Foreground Focus</strong>: We are primarily interested in whether the network can successfully segment objects in the foreground.</p></li>
<li><p><strong>Accuracy Balance</strong>: Background pixels can artificially inflate the overall accuracy, masking poor performance on foreground objects.</p></li>
</ol>
<p><strong>Notes:</strong></p>
<ol class="arabic simple">
<li><p><strong>Accuracy</strong>: The function ignores background pixels (labelled as <code class="docutils literal notranslate"><span class="pre">ignore_label</span></code>, default is 0) when reporting accuracy. This ensures the metric reflects the segmentation performance for foreground objects.</p></li>
<li><p><strong>Loss Function</strong>: The loss function still considers background pixels. This is often done to ensure that the model learns the distinction between background and foreground. However, if needed, we can modify the loss to ignore or down-weight background pixels.</p></li>
</ol>
<p><strong>Potential Enhancements:</strong></p>
<ul class="simple">
<li><p><strong>Ignore Background in Loss</strong>: You could modify the loss function to exclude background pixels entirely.</p></li>
<li><p><strong>Weighting Pixels</strong>: Assign different weights to pixels based on their type (e.g., foreground pixels might be given a higher weight)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">accuracy</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">ignore_label</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes pixel-wise accuracy, optionally ignoring specified labels.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        output (torch.Tensor): Model predictions with shape &lt;B, C, H, W&gt;.</span>
<span class="sd">        target (torch.Tensor): Ground truth labels with shape &lt;B, H, W&gt;.</span>
<span class="sd">        ignore_label (int): Label to ignore in accuracy computation (default=0).</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: Mean accuracy across all valid pixels.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Ensure computations are performed without gradients for efficiency</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="c1"># Convert predictions to class indices (highest probability for each pixel)</span>
        <span class="n">predicted_classes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Shape: &lt;B, H, W&gt;</span>
        
        <span class="c1"># Compare predictions to ground truth labels</span>
        <span class="n">correct_predictions</span> <span class="o">=</span> <span class="n">predicted_classes</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>  <span class="c1"># Shape: &lt;B, H, W&gt;</span>
        
        <span class="c1"># Exclude pixels with the ignored label</span>
        <span class="n">valid_pixels</span> <span class="o">=</span> <span class="n">target</span> <span class="o">!=</span> <span class="n">ignore_label</span>  <span class="c1"># Mask to filter out ignored pixels</span>
        
        <span class="c1"># Calculate the accuracy over valid pixels</span>
        <span class="n">valid_correct_predictions</span> <span class="o">=</span> <span class="n">correct_predictions</span><span class="p">[</span><span class="n">valid_pixels</span><span class="p">]</span>
        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">valid_correct_predictions</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>  <span class="c1"># Compute mean accuracy</span>
        
        <span class="k">return</span> <span class="n">accuracy</span>
</pre></div>
</div>
</div>
</div>
<p>To train and evaluate our model, we define a utility function called <code class="docutils literal notranslate"><span class="pre">epoch_loop</span></code>, which performs the operations required in each epoch. An <strong>epoch</strong> refers to one complete pass through the entire dataset—essentially, processing all samples in the dataset once.</p>
<p>Since much of the code for training and testing is similar, it’s efficient to combine both procedures into a single function. The parts that differ for training and testing can be separated within the function using conditional statements. For example, during training, we need to perform additional steps to update the model’s parameters:</p>
<ol class="arabic simple">
<li><p><strong>Compute the Gradient</strong>: We reset the gradients with <code class="docutils literal notranslate"><span class="pre">optimizer.zero_grad()</span></code>, ensuring that previous gradients do not interfere with the current update.</p></li>
<li><p><strong>Backpropagate the Loss</strong>: We calculate the gradients with <code class="docutils literal notranslate"><span class="pre">loss.backward()</span></code>, which backpropagates the loss to update each parameter in the network.</p></li>
<li><p><strong>Optimise the Weights</strong>: Finally, <code class="docutils literal notranslate"><span class="pre">optimizer.step()</span></code> adjusts the weights based on the computed gradients, helping the model learn from the errors.</p></li>
</ol>
<p><font color='red'><strong>Important</strong></font>: When evaluating (or testing) a model, it’s essential to call the <code class="docutils literal notranslate"><span class="pre">.eval()</span></code> method. This prevents certain layers (like dropout or batch normalisation) from updating, ensuring a consistent evaluation.</p>
<p><font color='red'><strong>Important</strong></font>: Also, use <code class="docutils literal notranslate"><span class="pre">torch.set_grad_enabled()</span></code> to specify whether gradients should be calculated (<code class="docutils literal notranslate"><span class="pre">True</span></code> during training and <code class="docutils literal notranslate"><span class="pre">False</span></code> during testing).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">epoch_loop</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">db_loader</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimiser</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Run a single epoch for training or testing.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        model (torch.nn.Module): The model to train/test.</span>
<span class="sd">        db_loader (DataLoader): Data loader for training or testing data.</span>
<span class="sd">        criterion (Loss Function): Loss function for computing the error.</span>
<span class="sd">        optimiser (torch.optim.Optimizer): Optimiser for training; if None, evaluation mode is assumed.</span>
<span class="sd">        </span>
<span class="sd">    Returns:</span>
<span class="sd">        accuracies (list): List of accuracies for each batch.</span>
<span class="sd">        losses (list): List of losses for each batch.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Determine whether in training mode</span>
    <span class="n">is_train</span> <span class="o">=</span> <span class="n">optimiser</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span> <span class="k">if</span> <span class="n">is_train</span> <span class="k">else</span> <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    
    <span class="n">accuracies</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="c1"># Disable gradient computation for evaluation</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">set_grad_enabled</span><span class="p">(</span><span class="n">is_train</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">batch_ind</span><span class="p">,</span> <span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">db_loader</span><span class="p">):</span>
            <span class="c1"># Move images and targets to device (GPU or CPU)</span>
            <span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">target</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            
            <span class="c1"># Forward pass: compute output and loss</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
            <span class="n">losses</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">))])</span>

            <span class="c1"># Compute accuracy</span>
            <span class="n">acc</span> <span class="o">=</span> <span class="n">accuracy</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">accuracies</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">acc</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">))])</span>
            
            <span class="c1"># Backward pass and optimisation step for training</span>
            <span class="k">if</span> <span class="n">is_train</span><span class="p">:</span>
                <span class="n">optimiser</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>   <span class="c1"># Reset gradients</span>
                <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>         <span class="c1"># Backpropagate loss</span>
                <span class="n">optimiser</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>        <span class="c1"># Update parameters</span>
    
    <span class="k">return</span> <span class="n">accuracies</span><span class="p">,</span> <span class="n">losses</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="experiments-with-uniform-background">
<h2>4. Experiments with Uniform Background<a class="headerlink" href="#experiments-with-uniform-background" title="Link to this heading">#</a></h2>
<p>In this section, we will evaluate the performance of our semantic segmentation model when the background pixels are uniform and free of noise. This controlled scenario helps us understand how well the model performs when there is no added complexity in distinguishing the foreground objects from the background.</p>
<section id="actual-learning">
<h3>Actual Learning<a class="headerlink" href="#actual-learning" title="Link to this heading">#</a></h3>
<p>With all components set up (data, model, loss, and optimiser), we can start the training and testing loop. In this example, we train the model for 10 epochs, meaning the model will go through all data points 10 times.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Dataset</span>
<span class="n">bg_type_probability</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># don&#39;t put noise in the background</span>

<span class="n">num_train_samples</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="c1"># Instantiate dataset for training</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">ShapeDataset</span><span class="p">(</span><span class="n">num_train_samples</span><span class="p">,</span> <span class="n">img_size</span><span class="p">,</span> <span class="n">bg_type_probability</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>

<span class="c1"># Set batch size</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">8</span>

<span class="c1"># Create DataLoader for training</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>

<span class="n">num_test_samples</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="c1"># Instantiate dataset for validation</span>
<span class="n">val_dataset</span> <span class="o">=</span> <span class="n">ShapeDataset</span><span class="p">(</span><span class="n">num_test_samples</span><span class="p">,</span> <span class="n">img_size</span><span class="p">,</span> <span class="n">bg_type_probability</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>

<span class="c1"># Create DataLoader for validation</span>
<span class="n">val_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">val_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>


<span class="c1"># Model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SimpleNet</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">label_to_shape</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">params_to_optimize</span> <span class="o">=</span> <span class="p">[{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()]}]</span>
<span class="n">momentum</span> <span class="o">=</span> <span class="mf">0.9</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">weight_decay</span> <span class="o">=</span> <span class="mf">1e-4</span>
<span class="n">optimiser</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span>
    <span class="n">params_to_optimize</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
    <span class="n">momentum</span><span class="o">=</span><span class="n">momentum</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span>
<span class="p">)</span>

<span class="c1"># Set the number of epochs for training</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">initial_epoch</span> <span class="o">=</span> <span class="mi">0</span>

<span class="c1"># Logs for tracking accuracy and loss over time</span>
<span class="n">train_logs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;acc&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="p">[]}</span>
<span class="n">val_logs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;acc&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="p">[]}</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">initial_epoch</span><span class="p">,</span> <span class="n">epochs</span><span class="p">):</span>
    <span class="c1"># Run a training epoch</span>
    <span class="n">train_log</span> <span class="o">=</span> <span class="n">epoch_loop</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimiser</span><span class="p">)</span>
    
    <span class="c1"># Run a validation epoch (no optimiser, so the model is in evaluation mode)</span>
    <span class="n">val_log</span> <span class="o">=</span> <span class="n">epoch_loop</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimiser</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    
    <span class="c1"># Print training and validation results for this epoch</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[Epoch </span><span class="si">%02d</span><span class="s1">] Train loss=</span><span class="si">%.4f</span><span class="s1">, acc=</span><span class="si">%.2f</span><span class="s1">  |  Test loss=</span><span class="si">%.4f</span><span class="s1">, acc=</span><span class="si">%.2f</span><span class="s1">&#39;</span> <span class="o">%</span> 
          <span class="p">(</span>
              <span class="n">epoch</span><span class="p">,</span> 
              <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_log</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_log</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
              <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">val_log</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">val_log</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
          <span class="p">))</span>
    
    <span class="c1"># Log the results for plotting later</span>
    <span class="n">train_logs</span><span class="p">[</span><span class="s1">&#39;acc&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_log</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">train_logs</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_log</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">val_logs</span><span class="p">[</span><span class="s1">&#39;acc&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">val_log</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">val_logs</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">val_log</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[Epoch 00] Train loss=0.2670, acc=0.12  |  Test loss=0.2679, acc=0.29
[Epoch 01] Train loss=0.1516, acc=0.36  |  Test loss=0.1560, acc=0.41
[Epoch 02] Train loss=0.1424, acc=0.37  |  Test loss=0.1365, acc=0.38
[Epoch 03] Train loss=0.1330, acc=0.40  |  Test loss=0.1307, acc=0.38
[Epoch 04] Train loss=0.1254, acc=0.42  |  Test loss=0.1201, acc=0.44
[Epoch 05] Train loss=0.0989, acc=0.58  |  Test loss=0.0837, acc=0.65
[Epoch 06] Train loss=0.0749, acc=0.69  |  Test loss=0.0656, acc=0.76
[Epoch 07] Train loss=0.0642, acc=0.77  |  Test loss=0.0612, acc=0.80
[Epoch 08] Train loss=0.0531, acc=0.83  |  Test loss=0.0523, acc=0.81
[Epoch 09] Train loss=0.0465, acc=0.86  |  Test loss=0.0481, acc=0.85
</pre></div>
</div>
</div>
</div>
</section>
<section id="reporting-results">
<h3>Reporting Results<a class="headerlink" href="#reporting-results" title="Link to this heading">#</a></h3>
<p>Finally, we’ll plot the accuracy and loss over the training epochs to evaluate the model’s performance. These plots can reveal if the model is improving over time or if adjustments are needed to hyperparameters.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot accuracy and loss over epochs</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="c1"># Plot accuracy</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_logs</span><span class="p">[</span><span class="s1">&#39;acc&#39;</span><span class="p">],</span> <span class="s1">&#39;-x&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">val_logs</span><span class="p">[</span><span class="s1">&#39;acc&#39;</span><span class="p">],</span> <span class="s1">&#39;-o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Model Accuracy&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch Number&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="c1"># Plot loss</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_logs</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="s1">&#39;-x&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">val_logs</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="s1">&#39;-o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Model Loss&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch Number&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/9bff8f6fe8a653b31643ed5b89d043bab48fb722f9eb4ddc893e576451d2fc4c.png" src="../_images/9bff8f6fe8a653b31643ed5b89d043bab48fb722f9eb4ddc893e576451d2fc4c.png" />
</div>
</div>
</section>
<section id="visualising-the-model-s-output">
<h3>Visualising the Model’s Output<a class="headerlink" href="#visualising-the-model-s-output" title="Link to this heading">#</a></h3>
<p>To better understand how the model interprets the data, we visualise its output for a single sample. This comparison includes:</p>
<ol class="arabic simple">
<li><p><strong>Input Image</strong>: The original image provided to the model.</p></li>
<li><p><strong>Ground Truth</strong>: The correct segmentation labels for the input image.</p></li>
<li><p><strong>Model Output</strong>: The segmentation predictions generated by the model.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">visualise_batch_output</span><span class="p">(</span><span class="n">data_loader</span><span class="p">,</span> <span class="n">max_imgs</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
    <span class="c1"># Iterate over the training data loader</span>
    <span class="k">for</span> <span class="n">batch_index</span><span class="p">,</span> <span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data_loader</span><span class="p">):</span>
        <span class="c1"># Move the input images and ground truth labels to the device (e.g., GPU or CPU)</span>
        <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">ground_truth</span> <span class="o">=</span> <span class="n">ground_truth</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        
        <span class="c1"># Forward pass: get model predictions for the batch of images</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
        <span class="k">break</span>  <span class="c1"># Exit after processing one batch for visualisation</span>
    
    <span class="c1"># Create a figure to display the input image, ground truth, and model output</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">22</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

    <span class="n">ax_ind</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">max_imgs</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">predictions</span><span class="p">))):</span>
        <span class="c1"># Display the input image</span>
        <span class="n">ax_ind</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">max_imgs</span> <span class="o">*</span> <span class="mi">3</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">ax_ind</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>  <span class="c1"># Remove axes for better visualisation</span>
        <span class="c1"># Transform image tensor back to RGB format and de-normalise it for visualisation</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="n">std</span> <span class="o">+</span> <span class="n">mean</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Input Image&#39;</span><span class="p">)</span>
        
        <span class="c1"># Display the ground truth labels as coloured segmentation</span>
        <span class="n">ax_ind</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">max_imgs</span> <span class="o">*</span> <span class="mi">3</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">ax_ind</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
        <span class="c1"># Convert the ground truth labels to a colour map for better visualisation</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">label_to_colour</span><span class="p">(</span><span class="n">ground_truth</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()))</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Ground Truth&#39;</span><span class="p">)</span>
        
        <span class="c1"># Display the model&#39;s predicted segmentation</span>
        <span class="n">ax_ind</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">max_imgs</span> <span class="o">*</span> <span class="mi">3</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">ax_ind</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
        <span class="c1"># Convert the predicted labels (argmax over channels) to a colour map</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">label_to_colour</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()))</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Model Output&#39;</span><span class="p">)</span>
    
    <span class="c1"># Show the plots</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">visualise_batch_output</span><span class="p">(</span><span class="n">val_loader</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/7754654452606ecd1a36346e700a603432203563c2055c4376fcfda557b99c4b.png" src="../_images/7754654452606ecd1a36346e700a603432203563c2055c4376fcfda557b99c4b.png" />
</div>
</div>
</section>
</section>
<section id="experiment-with-noise">
<h2>5. Experiment With Noise<a class="headerlink" href="#experiment-with-noise" title="Link to this heading">#</a></h2>
<p>From the results above, we can obseer that quantitativeley and qualitativeley we obtain decent segmentation resutls for our tox example in relativeley a few numebr fo epochs.</p>
<p>Let’s experiment with a more complex dataset with noisy backgrounds.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Dataset</span>
<span class="n">bg_type_probability</span> <span class="o">=</span> <span class="mf">0.5</span>  <span class="c1"># add noise half of the time</span>

<span class="n">num_train_samples</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="c1"># Instantiate dataset for training</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">ShapeDataset</span><span class="p">(</span><span class="n">num_train_samples</span><span class="p">,</span> <span class="n">img_size</span><span class="p">,</span> <span class="n">bg_type_probability</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>

<span class="c1"># Set batch size</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">8</span>

<span class="c1"># Create DataLoader for training</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>

<span class="n">num_test_samples</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="c1"># Instantiate dataset for validation</span>
<span class="n">val_dataset</span> <span class="o">=</span> <span class="n">ShapeDataset</span><span class="p">(</span><span class="n">num_test_samples</span><span class="p">,</span> <span class="n">img_size</span><span class="p">,</span> <span class="n">bg_type_probability</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>

<span class="c1"># Create DataLoader for validation</span>
<span class="n">val_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">val_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>


<span class="c1"># Model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SimpleNet</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">label_to_shape</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">params_to_optimize</span> <span class="o">=</span> <span class="p">[{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()]}]</span>
<span class="n">momentum</span> <span class="o">=</span> <span class="mf">0.9</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">weight_decay</span> <span class="o">=</span> <span class="mf">1e-4</span>
<span class="n">optimiser</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span>
    <span class="n">params_to_optimize</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
    <span class="n">momentum</span><span class="o">=</span><span class="n">momentum</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span>
<span class="p">)</span>

<span class="c1"># Set the number of epochs for training</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">initial_epoch</span> <span class="o">=</span> <span class="mi">0</span>

<span class="c1"># Logs for tracking accuracy and loss over time</span>
<span class="n">train_logs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;acc&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="p">[]}</span>
<span class="n">val_logs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;acc&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="p">[]}</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">initial_epoch</span><span class="p">,</span> <span class="n">epochs</span><span class="p">):</span>
    <span class="c1"># Run a training epoch</span>
    <span class="n">train_log</span> <span class="o">=</span> <span class="n">epoch_loop</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimiser</span><span class="p">)</span>
    
    <span class="c1"># Run a validation epoch (no optimiser, so the model is in evaluation mode)</span>
    <span class="n">val_log</span> <span class="o">=</span> <span class="n">epoch_loop</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimiser</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    
    <span class="c1"># Print training and validation results for this epoch</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[Epoch </span><span class="si">%02d</span><span class="s1">] Train loss=</span><span class="si">%.4f</span><span class="s1">, acc=</span><span class="si">%.2f</span><span class="s1">  |  Test loss=</span><span class="si">%.4f</span><span class="s1">, acc=</span><span class="si">%.2f</span><span class="s1">&#39;</span> <span class="o">%</span> 
          <span class="p">(</span>
              <span class="n">epoch</span><span class="p">,</span> 
              <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_log</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_log</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
              <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">val_log</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">val_log</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
          <span class="p">))</span>
    
    <span class="c1"># Log the results for plotting later</span>
    <span class="n">train_logs</span><span class="p">[</span><span class="s1">&#39;acc&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_log</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">train_logs</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_log</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">val_logs</span><span class="p">[</span><span class="s1">&#39;acc&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">val_log</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">val_logs</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">val_log</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[Epoch 00] Train loss=0.2862, acc=0.06  |  Test loss=0.2275, acc=0.22
[Epoch 01] Train loss=0.1834, acc=0.33  |  Test loss=0.1615, acc=0.35
[Epoch 02] Train loss=0.1568, acc=0.35  |  Test loss=0.1488, acc=0.36
[Epoch 03] Train loss=0.1557, acc=0.34  |  Test loss=0.1588, acc=0.36
[Epoch 04] Train loss=0.1443, acc=0.37  |  Test loss=0.1436, acc=0.36
[Epoch 05] Train loss=0.1396, acc=0.38  |  Test loss=0.1327, acc=0.38
[Epoch 06] Train loss=0.1363, acc=0.39  |  Test loss=0.1316, acc=0.38
[Epoch 07] Train loss=0.1325, acc=0.41  |  Test loss=0.1297, acc=0.40
[Epoch 08] Train loss=0.1309, acc=0.46  |  Test loss=0.1288, acc=0.48
[Epoch 09] Train loss=0.1204, acc=0.52  |  Test loss=0.1152, acc=0.53
</pre></div>
</div>
</div>
</div>
<section id="id1">
<h3>Reporting Results<a class="headerlink" href="#id1" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot accuracy and loss over epochs</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="c1"># Plot accuracy</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_logs</span><span class="p">[</span><span class="s1">&#39;acc&#39;</span><span class="p">],</span> <span class="s1">&#39;-x&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">val_logs</span><span class="p">[</span><span class="s1">&#39;acc&#39;</span><span class="p">],</span> <span class="s1">&#39;-o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Model Accuracy&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch Number&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="c1"># Plot loss</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_logs</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="s1">&#39;-x&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">val_logs</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="s1">&#39;-o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Model Loss&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch Number&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/e179184459347d0fc77c8742823dffdfee798db9b88f4274ff3e2d4160980187.png" src="../_images/e179184459347d0fc77c8742823dffdfee798db9b88f4274ff3e2d4160980187.png" />
</div>
</div>
</section>
<section id="id2">
<h3>Visualising the Model’s Output<a class="headerlink" href="#id2" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">visualise_batch_output</span><span class="p">(</span><span class="n">val_loader</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/a98b6fd8dd22af5b845d7f7fde2d9e1999edc870d48ed8ea9c56e6fcb4cac996.png" src="../_images/a98b6fd8dd22af5b845d7f7fde2d9e1999edc870d48ed8ea9c56e6fcb4cac996.png" />
</div>
</div>
</section>
</section>
<section id="exercises">
<h2>6. Exercises<a class="headerlink" href="#exercises" title="Link to this heading">#</a></h2>
<p>In this notebook, we built a simple semantic segmentation network that predicts the category label of each pixel. Here are some exercises to help you explore and enhance your understanding of the model and its components:</p>
<ol class="arabic simple">
<li><p><strong>Increase the complexity of your dataset by including additional geometrical shapes</strong><br />
Currently, your dataset consists of a limited set of geometrical shapes. You can increase the complexity by adding other shapes like stars, or irregular polygons. You can also set <code class="docutils literal notranslate"><span class="pre">is_filled</span></code> to <code class="docutils literal notranslate"><span class="pre">False</span></code>. How does the model perform with a more challenging dataset? Does the network require more training or different architectural modifications to handle the added complexity?</p></li>
<li><p><strong>The accuracy for the experiment with background noise is not as high. How can you obtain higher accuracy?</strong><br />
In the experiment where the background contains noise, the model’s accuracy might be lower. What changes can you make to improve accuracy?</p></li>
<li><p><strong>Ignore background in loss function:</strong><br />
Modify the loss function to exclude background pixels from the computation of the loss. This means that only the foreground pixels will contribute to the loss. How does excluding the background affect the performance of the model, especially with noisy backgrounds? Experiment with different loss functions and assess their impact on accuracy.</p></li>
<li><p><strong>Weighting Pixels:</strong><br />
Instead of ignoring background pixels entirely, you can assign different weights to pixels based on their type. For example, foreground pixels could have a higher weight than background pixels. Modify the loss function to apply these weights. How does this affect the model’s performance? Does it help the network focus more on the foreground objects during training?</p></li>
</ol>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="image_classification.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">4.1. Image Classification</p>
      </div>
    </a>
    <a class="right-next"
       href="transfer_learning.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">4.3. Transfer Learning</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preparation">0. Preparation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#required-packages">Required Packages</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset">1. Dataset</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-utility-functions">Dataset Utility Functions</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-backgrounds">Creating Backgrounds</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#drawing-foreground-shapes">Drawing Foreground Shapes</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-tiled-images">Creating Tiled Images</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#visualising-the-dataset">Visualising the Dataset</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch-data-pipeline">PyTorch Data Pipeline</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#data-augmentation">Data Augmentation</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#data-transformations">Data Transformations</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#dataloader-managing-data-batches">DataLoader: Managing Data Batches</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model">2. Model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#architecture">Architecture</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#image-classification">Image Classification</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#semantic-segmentation">Semantic Segmentation</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#network">Network</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-and-testing-routines">3. Training and Testing Routines</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optimiser">Optimiser</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#loss-function">Loss Function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-utility-functions">Training utility functions</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#experiments-with-uniform-background">4. Experiments with Uniform Background</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#actual-learning">Actual Learning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#reporting-results">Reporting Results</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualising-the-model-s-output">Visualising the Model’s Output</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#experiment-with-noise">5. Experiment With Noise</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Reporting Results</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Visualising the Model’s Output</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">6. Exercises</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Arash Akbarinia
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>