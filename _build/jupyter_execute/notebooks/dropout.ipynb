{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64e9684b-d3c3-4b78-95f3-c446c40e2be3",
   "metadata": {},
   "source": [
    "# 1.6. Dropout\n",
    "\n",
    "**Dropout** is a regularisation technique that randomly sets a fraction of input units to zero during training.\n",
    "By temporarily removing neurons and their connections, the network becomes less dependent on specific features, improving its ability to generalise to unseen data.\n",
    "\n",
    "Dropout is a simple yet powerful method to reduce overfitting. It works by preventing the **co-adaptation** of neuronsâ€”forcing them to learn more robust and independent representations. The method was introduced by [Hinton et al. (2012)](https://arxiv.org/abs/1207.0580) in their paper *Improving neural networks by preventing co-adaptation of feature detectors*.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/DeepLearning-JupyterBook/deeplearning-jupyterbook.github.io/refs/heads/master/imgs/dropout_demo.gif\" alt=\"Dropout demonstration\" width=\"600\"/>\n",
    "\n",
    "**Key points:**\n",
    "\n",
    "* Dropout is **enabled only during training** (`model.train()`).\n",
    "* During **evaluation** (`model.eval()`), dropout is **disabled**.\n",
    "* When active, dropout **scales** the remaining neurons to maintain the same expected output sum.\n",
    "* The dropout probability `p` controls how many neurons are randomly turned off (e.g., `p = 0.5` drops half of them)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6f757d-f6cb-4604-a892-c5e1419ea478",
   "metadata": {},
   "source": [
    "## 0. Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cc64fb6-c013-4cf7-be0e-3f7bb4e8974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2213df51-f152-4976-b47c-b20805b0b06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor x:\n",
      "tensor([[1., 2., 3., 4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# Create a simple tensor (batch of 1 sample, 6 features)\n",
    "x = torch.tensor([[1., 2., 3., 4., 5., 6.]])\n",
    "print(\"Input tensor x:\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8de8af8e-5df0-4e0d-9617-e98e3866ef0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dropout layer\n",
    "dropout_prob = 0.5  # fraction of neurons to drop\n",
    "drop_nodes = nn.Dropout(p=dropout_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dc605d-495d-4394-bcd4-c6e5a6070f7b",
   "metadata": {},
   "source": [
    "## 1. Train mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba087dd2-e4dd-4309-b76f-480a2fcd6264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after Dropout (training mode):\n",
      "tensor([[ 0.,  4.,  6.,  8., 10.,  0.]])\n"
     ]
    }
   ],
   "source": [
    "# Enable training mode to activate dropout\n",
    "drop_nodes.train()\n",
    "y_train = drop_nodes(x)\n",
    "\n",
    "print(\"Output after Dropout (training mode):\")\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7383d1cd-3ac1-43ff-bda0-3d780a73cf00",
   "metadata": {},
   "source": [
    "Notice that **some values are set to 0**, and the remaining values are **scaled** by $\\frac{1}{1-p}$ to maintain the expected sum. Here `p = 0.5`, so the non-dropped values are multiplied by 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd29a7d-c008-4dce-95f4-0e6738fefb66",
   "metadata": {},
   "source": [
    "## 2. Eval mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "453462d7-b8a2-4caf-8131-1a2340ae4b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output in evaluation mode (no dropout applied):\n",
      "tensor([[1., 2., 3., 4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# Evaluate mode (Dropout disabled)\n",
    "drop_nodes.eval()\n",
    "y_eval = drop_nodes(x)\n",
    "\n",
    "print(\"Output in evaluation mode (no dropout applied):\")\n",
    "print(y_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43275db4-da09-4ec9-a2d5-df32802753c5",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- **Training mode:** Randomly drops units according to probability `p` and scales remaining ones.\n",
    "- Every run drops **different neurons**, introducing variability and regularisation.\n",
    "- **Evaluation mode:** No units are dropped; tensor passes through unchanged.\n",
    "- Dropout is commonly applied **after fully connected layers** or **after activations** in a neural network.\n",
    "\n",
    "Takeaway: Dropout **prevents the network from relying too much on specific neurons**, which helps reduce overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}