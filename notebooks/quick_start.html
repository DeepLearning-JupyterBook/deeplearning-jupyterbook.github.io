
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>2. Quick Start &#8212; Deep Learning for Experimental Psychologists and Cognitive Neuroscientists</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=36754332"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-BXYWD71FWS"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-BXYWD71FWS');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-BXYWD71FWS');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/quick_start';</script>
    <link rel="icon" href="../_static/icon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="3. Optimisation and Learning" href="optimisation_learning.html" />
    <link rel="prev" title="1.6. Dropout" href="dropout.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Deep Learning for Experimental Psychologists and Cognitive Neuroscientists - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Deep Learning for Experimental Psychologists and Cognitive Neuroscientists - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Welcome
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Prerequisites</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../markdowns/environment_setup.html">0. Environment Setup</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="networks_building_blocks.html">1. Network’s Building Blocks</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="convolution.html">1.1. Convolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="activation_function.html">1.2. Activation Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="pooling.html">1.3. Pooling</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear.html">1.4. Linear Layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="normalisation.html">1.5. Normalisation</a></li>
<li class="toctree-l2"><a class="reference internal" href="dropout.html">1.6. Dropout</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">2. Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="optimisation_learning.html">3. Optimisation and Learning</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="vision.html">4. Vision</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="image_classification.html">4.1. Image Classification</a></li>





<li class="toctree-l2"><a class="reference internal" href="image_segmentation.html">4.2. Image Segmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="transfer_learning.html">4.3. Transfer Learning</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="other_modalities.html">5. Other Modalities</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="audio_classification.html">5.1. Audio Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="text_classification.html">5.2. Text Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="clip.html">5.3. Language – Vision</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="generative_models.html">6. Deep Generative Models</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="gan.html">6.1. Generative Adversarial Network</a></li>






<li class="toctree-l2"><a class="reference internal" href="vae.html">6.2. Deep Autoencoder</a></li>







<li class="toctree-l2"><a class="reference internal" href="dpm.html">6.3. Diffusion Probabilistic Model</a></li>






<li class="toctree-l2"><a class="reference internal" href="llm.html">6.4. Large Language Model</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="interpretation_techniques.html">7. Interpretation Techniques</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="activation.html">7.1. Activation Maps</a></li>
<li class="toctree-l2"><a class="reference internal" href="lesion.html">7.2. Kernel Lesioning</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_classifier_probe.html">7.3. Probing by linear classifiers</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro-to-rsa.html">7.4. Representational Similarity Analysis</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="big_projects.html">8. Big Projects</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../markdowns/python_scripting.html">8.1. Python Scripting</a></li>
<li class="toctree-l2"><a class="reference internal" href="tensorboard.html">8.2. TensorBoard</a></li>
<li class="toctree-l2"><a class="reference internal" href="../markdowns/server.html">8.3. Working with Servers</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="reinforcement_learning.html">9. Reinforcement Learning</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Assignments</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="assignments/warmup.html">Warming-up</a></li>
<li class="toctree-l1"><a class="reference internal" href="assignments/optimisation_learning.html">Optimisation and Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="assignments/llm_assignment.html">LLM Calculator</a></li>
<li class="toctree-l1"><a class="reference internal" href="assignments/zeroshot_evaluation.html">Zero-shot Evaluation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Student Projects</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="student_projects/deep-learning-with-dobble.html">Deep Learning with Dobble</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Complementary Materials</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="python_course/beginners.html">Python For Beginners</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="python_course/dataTypes.html">Data Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="python_course/modules.html">Modules and NumPy Arrays</a></li>
<li class="toctree-l2"><a class="reference internal" href="python_course/conditions.html">Conditions</a></li>
<li class="toctree-l2"><a class="reference internal" href="python_course/loops.html">Loops</a></li>
<li class="toctree-l2"><a class="reference internal" href="python_course/plotting.html">Plotting</a></li>
<li class="toctree-l2"><a class="reference internal" href="python_course/functions.html">Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="python_course/moduleObjects.html">Modules and Objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="python_course/inheritance.html">Inheritance</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/DeepLearning-JupyterBook/deeplearning-jupyterbook.github.io/blob/master/notebooks/quick_start.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/DeepLearning-JupyterBook/deeplearning-jupyterbook.github.io" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/DeepLearning-JupyterBook/deeplearning-jupyterbook.github.io/edit/master//notebooks/quick_start.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/DeepLearning-JupyterBook/deeplearning-jupyterbook.github.io/issues/new?title=Issue%20on%20page%20%2Fnotebooks/quick_start.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/notebooks/quick_start.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>2. Quick Start</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preparation">0. Preparation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#required-packages">Required Packages</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset">1. Dataset</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-utility-functions">Dataset Utility Functions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-and-testing-sets">Training and Testing Sets</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-visualisation">Dataset Visualisation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch-data-pipeline">PyTorch Data Pipeline</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-transformations">Data Transformations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dataloader-managing-data-batches">DataLoader: Managing Data Batches</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model">2. Model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#architecture">Architecture</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#network">Network</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-and-testing-routines">3. Training and Testing Routines</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optimiser">Optimiser</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#loss-function">Loss Function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-testing-utility-functions">Training-testing Utility Functions</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#actual-learning">4. Actual Learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reporting-results">5. Reporting Results</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">Exercises</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implementing-a-dataloader-to-load-images-from-disk">1. Implementing a Dataloader to Load Images from Disk</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exploring-the-effect-of-background-colour-in-training-and-testing">2. Exploring the Effect of Background Colour in Training and Testing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#adding-new-geometrical-shapes-to-the-dataset">3. Adding New Geometrical Shapes to the Dataset</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="quick-start">
<h1>2. Quick Start<a class="headerlink" href="#quick-start" title="Link to this heading">#</a></h1>
<p>In this notebook, we’ll learn how to create a complete deep learning project in PyTorch. Broadly, a project consists of three main components:</p>
<ul class="simple">
<li><p>Preparing the dataset and defining the task</p></li>
<li><p>Designing the architecture of the neural network</p></li>
<li><p>Implementing the training and testing routines</p></li>
</ul>
<p>To keep things clear, we’ll work on a simple example where the network classifies basic geometric shapes (like circles, squares, and triangles) in images. This will help us focus on the main steps without overwhelming details.</p>
<section id="preparation">
<h2>0. Preparation<a class="headerlink" href="#preparation" title="Link to this heading">#</a></h2>
<p>Before we dive into the project, let’s start by preparing the necessary materials.</p>
<section id="required-packages">
<h3>Required Packages<a class="headerlink" href="#required-packages" title="Link to this heading">#</a></h3>
<p>We will use several Python libraries, each serving a specific role:</p>
<ul class="simple">
<li><p><strong><a class="reference external" href="https://numpy.org/">numpy</a>:</strong> The main library for scientific computing in Python, commonly imported as <code class="docutils literal notranslate"><span class="pre">np</span></code>.</p></li>
<li><p><strong><a class="reference external" href="https://matplotlib.org/">matplotlib</a>:</strong> Useful for plotting graphs and visualising data.</p></li>
<li><p><strong><a class="reference external" href="https://pytorch.org/docs/stable/index.html">torch</a>:</strong> The core library in PyTorch for deep learning, helping us define and manage neural networks.</p></li>
<li><p><strong><a class="reference external" href="https://pytorch.org/vision/stable/index.html">torchvision</a>:</strong> Contains tools and datasets for computer vision tasks.</p></li>
<li><p><strong><a class="reference external" href="https://docs.opencv.org/4.x/index.html">cv2</a> (OpenCV):</strong> A widely-used library for image processing.</p></li>
</ul>
<p>Let’s import these libraries now:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># importing the necessary packages/libraries</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">matplotlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">random</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torchvision</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">cv2</span>
</pre></div>
</div>
</div>
</div>
<p>Deep learning tasks can be computationally demanding. GPUs are often used because they are designed to handle complex calculations efficiently. In this case, if a <strong>GPU</strong> is available, PyTorch will use it; otherwise, it will default to using the <strong>CPU</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Automatically selects GPU if available, else defaults to CPU</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="dataset">
<h2>1. Dataset<a class="headerlink" href="#dataset" title="Link to this heading">#</a></h2>
<p>In deep learning, it’s often practical to start by considering the dataset and task you’re working with. In many real-world projects, we already have a dataset that we load from disk. However, in this example, we’ll create a small dataset on the fly within the notebook.</p>
<p>We will create images containing one of three geometric shapes:</p>
<ol class="arabic simple">
<li><p>Circle</p></li>
<li><p>Ellipse</p></li>
<li><p>Rectangle</p></li>
</ol>
<p>Each image will contain only one shape on a background, and our task is to classify the shape in each image. This task is known as <strong>image classification</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the labels for our shapes</span>
<span class="n">labels_map</span> <span class="o">=</span> <span class="p">{</span>
    <span class="mi">0</span><span class="p">:</span> <span class="s2">&quot;circle&quot;</span><span class="p">,</span>
    <span class="mi">1</span><span class="p">:</span> <span class="s2">&quot;ellipse&quot;</span><span class="p">,</span>
    <span class="mi">2</span><span class="p">:</span> <span class="s2">&quot;rectangle&quot;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<section id="dataset-utility-functions">
<h3>Dataset Utility Functions<a class="headerlink" href="#dataset-utility-functions" title="Link to this heading">#</a></h3>
<p>We’ll now write helper functions to generate our dataset. Specifically, we’ll create two functions:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">create_random_background</span></code>: This function will generate a background for each image.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">create_random_shape</span></code>: This function will add a shape to the background.</p></li>
</ul>
<p>Let’s look at each function in detail.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">create_random_background</span><span class="p">(</span><span class="n">img_size</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Creates a background for an image. </span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        img_size (int): Size of the background (image will be square).</span>
<span class="sd">        p (float): Probability of generating a random noise background.</span>
<span class="sd">        </span>
<span class="sd">    Returns:</span>
<span class="sd">        numpy array: Background image of size (img_size, img_size, 3).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># If a randomly generated number is above p, create a noise background; otherwise, use a uniform colour</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">&gt;</span> <span class="n">p</span><span class="p">:</span>
        <span class="c1"># Random noise background: random pixel values for each RGB channel</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="p">(</span><span class="n">img_size</span><span class="p">,</span> <span class="n">img_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;uint8&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Uniform background: same colour for each pixel</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">img_size</span><span class="p">,</span> <span class="n">img_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;uint8&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;uint8&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>This function creates a random background for our image. Sometimes it’s just a uniform colour (like a single shade), while other times it’s a random noise background (each pixel has a random colour).</p></li>
<li><p>By creating different types of backgrounds, we introduce some <strong>variation</strong> to make the task slightly more challenging.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">create_random_shape</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">filled</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Draws a random shape (circle, ellipse, or rectangle) on the given background image.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        img (numpy array): Background image on which to draw the shape.</span>
<span class="sd">        filled (bool): If True, shapes will be filled; otherwise, they will be outlined.</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">        tuple: Modified image with shape and shape label (int).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Generate a random colour for the shape</span>
    <span class="n">colour</span> <span class="o">=</span> <span class="p">[</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)]</span>
    <span class="n">thickness</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
    <span class="n">point1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span> <span class="o">*</span> <span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="mi">4</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>

    <span class="c1"># Select a random shape (circle, ellipse, or rectangle)</span>
    <span class="n">shape_ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels_map</span><span class="p">))</span>
    <span class="c1"># Set shape to be filled if `filled` is True</span>
    <span class="n">thickness</span> <span class="o">*=</span> <span class="o">-</span><span class="mi">1</span> <span class="k">if</span> <span class="n">filled</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

    <span class="k">if</span> <span class="n">shape_ind</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># Circle</span>
        <span class="n">radius</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="mi">4</span><span class="p">)</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">circle</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">point1</span><span class="p">),</span> <span class="n">radius</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colour</span><span class="p">,</span> <span class="n">thickness</span><span class="o">=</span><span class="n">thickness</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">shape_ind</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># Ellipse</span>
        <span class="n">axes</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="mi">4</span><span class="p">)]</span>
        <span class="n">angle</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">360</span><span class="p">)</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">ellipse</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">point1</span><span class="p">),</span> <span class="n">axes</span><span class="p">,</span> <span class="n">angle</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">360</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colour</span><span class="p">,</span> <span class="n">thickness</span><span class="o">=</span><span class="n">thickness</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>  <span class="c1"># Rectangle</span>
        <span class="n">point2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">rectangle</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">point1</span><span class="p">),</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">point2</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="n">colour</span><span class="p">,</span> <span class="n">thickness</span><span class="o">=</span><span class="n">thickness</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">img</span><span class="p">,</span> <span class="n">shape_ind</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>This function draws a randomly chosen shape on the background.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">shape_ind</span></code> specifies which shape to draw (circle, ellipse, or rectangle), and <code class="docutils literal notranslate"><span class="pre">filled</span></code> determines whether the shape is filled or just outlined.</p></li>
<li><p>The function returns both the modified image and the label of the shape (used later for training).</p></li>
</ul>
</section>
<section id="training-and-testing-sets">
<h3>Training and Testing Sets<a class="headerlink" href="#training-and-testing-sets" title="Link to this heading">#</a></h3>
<p>We usually divide data into three parts: <strong>training</strong>, <strong>validation</strong>, and <strong>testing</strong>:</p>
<ul class="simple">
<li><p><strong>Training Set</strong>: Used for learning.</p></li>
<li><p><strong>Validation Set</strong>: Used to fine-tune parameters.</p></li>
<li><p><strong>Test Set</strong>: Used to evaluate the model.</p></li>
</ul>
<p>To ensure the model generalises well, a rule of thumb is 70% training, 15% validation, and 15% testing.
Validation data can be utilised for hyperparameter tuning, such as identifying the best optimiser algorithm and the optimal learning rate. The test set must never be used in any part of the training process.</p>
<p><img alt="Dataset Split" src="https://blog.kakaocdn.net/dn/UenrJ/btrk6fXBfbJ/4iGSlrWj4mVJxzmup2KVr1/img.png" /></p>
<p>In our case, we’ll create two sets of images: one for training and one for testing. We skipped the validation, because we’re not doing any hyper parameter tunning.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">make_image_set</span><span class="p">(</span><span class="n">num_imgs</span><span class="p">,</span> <span class="n">img_size</span><span class="p">,</span> <span class="n">bg_p</span><span class="p">,</span> <span class="n">filled</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generates a dataset of images containing random shapes.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        num_imgs (int): Number of images to create.</span>
<span class="sd">        img_size (int): Size of each image (square).</span>
<span class="sd">        bg_p (float): Probability of a uniform background.</span>
<span class="sd">        filled (bool): Whether shapes are filled or outlined.</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">        list: Images and corresponding shape labels.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">imgs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">gts</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_imgs</span><span class="p">):</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">create_random_background</span><span class="p">(</span><span class="n">img_size</span><span class="p">,</span> <span class="n">bg_p</span><span class="p">)</span>
        <span class="n">img</span><span class="p">,</span> <span class="n">gt</span> <span class="o">=</span> <span class="n">create_random_shape</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">filled</span><span class="p">)</span>
        <span class="n">imgs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
        <span class="n">gts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">gt</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">imgs</span><span class="p">,</span> <span class="n">gts</span>
</pre></div>
</div>
</div>
</div>
<p>Here, <code class="docutils literal notranslate"><span class="pre">make_image_set</span></code> generates a set of images based on the specified number and size.</p>
<p><strong>Note</strong>: this functoins cannot be scaled to large datasets as it loads all images into a large list. For instance, if we want to have one million images, we run out of memory.</p>
<p><strong>Exercise:</strong> Consider how this function could be modified to handle very large datasets.</p>
<p>Next, we create a trarin set of 1000 images and a test set of 100 images.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Parameters for the dataset</span>
<span class="n">img_size</span> <span class="o">=</span> <span class="mi">128</span>  <span class="c1"># Image size (128 x 128 pixels)</span>
<span class="n">filled</span> <span class="o">=</span> <span class="kc">True</span>  <span class="c1"># Choose whether shapes are filled or outlined</span>
<span class="n">bg_uniform_vs_noise</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># Probability of uniform background</span>

<span class="c1"># Create training and test sets</span>
<span class="n">number_trains</span> <span class="o">=</span> <span class="mi">1000</span>  <span class="c1"># Number of training images</span>
<span class="n">number_test</span> <span class="o">=</span> <span class="n">number_trains</span> <span class="o">//</span> <span class="mi">10</span>  <span class="c1"># Number of test images</span>

<span class="c1"># Generate image datasets</span>
<span class="n">train_imgs</span><span class="p">,</span> <span class="n">train_gts</span> <span class="o">=</span> <span class="n">make_image_set</span><span class="p">(</span><span class="n">number_trains</span><span class="p">,</span> <span class="n">img_size</span><span class="p">,</span> <span class="n">bg_p</span><span class="o">=</span><span class="n">bg_uniform_vs_noise</span><span class="p">,</span> <span class="n">filled</span><span class="o">=</span><span class="n">filled</span><span class="p">)</span>
<span class="n">test_imgs</span><span class="p">,</span> <span class="n">test_gts</span> <span class="o">=</span> <span class="n">make_image_set</span><span class="p">(</span><span class="n">number_test</span><span class="p">,</span> <span class="n">img_size</span><span class="p">,</span> <span class="n">bg_p</span><span class="o">=</span><span class="n">bg_uniform_vs_noise</span><span class="p">,</span> <span class="n">filled</span><span class="o">=</span><span class="n">filled</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="dataset-visualisation">
<h3>Dataset Visualisation<a class="headerlink" href="#dataset-visualisation" title="Link to this heading">#</a></h3>
<p>Let’s look at a sample of our generated images to verify they appear as expected. Using <code class="docutils literal notranslate"><span class="pre">plt</span></code> from <code class="docutils literal notranslate"><span class="pre">matplotlib</span></code>, we’ll create a grid of images with their corresponding shape label (ground truth).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># plot 50 of the images</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">50</span><span class="p">):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">train_imgs</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;GT=</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">labels_map</span><span class="p">[</span><span class="n">train_gts</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/637185db4dc55488658b355559bc6448a5c936a11c3bc15c733eb8a543521a93.png" src="../_images/637185db4dc55488658b355559bc6448a5c936a11c3bc15c733eb8a543521a93.png" />
</div>
</div>
</section>
<section id="pytorch-data-pipeline">
<h3>PyTorch Data Pipeline<a class="headerlink" href="#pytorch-data-pipeline" title="Link to this heading">#</a></h3>
<p>Now that we have created our dataset, we need to create <strong>PyTorch dataloaders</strong> to efficiently manage and load our data during model training and evaluation. PyTorch dataloaders make it easier to handle large datasets by loading small batches of data sequentially, which is essential for efficient memory usage and faster processing.</p>
<p>In this example, we define a custom dataloader class, <code class="docutils literal notranslate"><span class="pre">ShapeDataset</span></code>, by inheriting from <code class="docutils literal notranslate"><span class="pre">torch.utils.data.Dataset</span></code>. Custom datasets in PyTorch should implement two main functions:</p>
<ol class="arabic simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">__len__</span></code></strong>: Returns the number of samples in the dataset.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">__getitem__</span></code></strong>: Retrieves a specific sample from the dataset, based on the provided index.</p></li>
</ol>
<p>In deep learning, datasets are often very large (for example, ImageNet contains 1.5 million images). Loading all images into memory at once would require a vast amount of memory, so instead, we load each image dynamically within the <code class="docutils literal notranslate"><span class="pre">__getitem__</span></code> function. This approach helps us manage memory effectively, especially when working with limited computational resources.</p>
<p>With this structure, you can customise datasets for any purpose by creating similar classes with a defined initialisation (<code class="docutils literal notranslate"><span class="pre">__init__</span></code>), length (<code class="docutils literal notranslate"><span class="pre">__len__</span></code>), and retrieval (<code class="docutils literal notranslate"><span class="pre">__getitem__</span></code>) functionality.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># PyTorch Dataset Class for Shape Data</span>
<span class="k">class</span><span class="w"> </span><span class="nc">ShapeDataset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">imgs</span><span class="p">,</span> <span class="n">gts</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialise the dataset with images, ground-truth labels, and optional transformations.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            imgs (list or array): List of images.</span>
<span class="sd">            gts (list or array): Ground-truth labels associated with each image.</span>
<span class="sd">            transform (callable, optional): Transformations to be applied to each image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">imgs</span> <span class="o">=</span> <span class="n">imgs</span>        <span class="c1"># Store images</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gts</span> <span class="o">=</span> <span class="n">gts</span>          <span class="c1"># Store ground-truth labels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span>  <span class="c1"># Store transformations (if any)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the total number of samples in the dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">imgs</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Retrieves a sample and its ground-truth label by index.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            idx (int): Index of the sample.</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            tuple: Transformed image and its corresponding ground-truth label.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Get image and label for the given index</span>
        <span class="n">img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">imgs</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="n">gt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gts</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>  <span class="c1"># gt = ground truth, representing the shape&#39;s ID here</span>

        <span class="c1"># Apply transformation if specified</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">:</span>
            <span class="n">img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>

        <span class="c1"># Return the image and its label as a tuple</span>
        <span class="k">return</span> <span class="n">img</span><span class="p">,</span> <span class="n">gt</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><strong>Initialisation (<code class="docutils literal notranslate"><span class="pre">__init__</span></code>)</strong>: This function sets up the dataset. It typically receives and stores all the necessary data (e.g., <code class="docutils literal notranslate"><span class="pre">imgs</span></code> for images, <code class="docutils literal notranslate"><span class="pre">gts</span></code> for ground-truth labels). It also takes in a <code class="docutils literal notranslate"><span class="pre">transform</span></code> parameter to allow for optional transformations on each sample. In practice, only paths to the images might be loaded, while the actual image data is loaded dynamically in <code class="docutils literal notranslate"><span class="pre">__getitem__</span></code>.</p></li>
<li><p><strong>Data Transformations (<code class="docutils literal notranslate"><span class="pre">transform</span></code>)</strong>: Transformations are critical in deep learning workflows to ensure data is processed consistently and to improve model performance by applying operations such as normalisation and data augmentation. Let’s discuss transformations in more detail.</p></li>
</ul>
</section>
<section id="data-transformations">
<h3>Data Transformations<a class="headerlink" href="#data-transformations" title="Link to this heading">#</a></h3>
<p>In this example, we use two standard transformations:</p>
<ol class="arabic simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">ToTensor</span></code></strong>: Converts an image into a PyTorch tensor. PyTorch models work with tensors, so we must apply this transformation before feeding data into our model.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">Normalize</span></code></strong>: Scales image pixel values so they are centred around zero. This is important because many deep learning models perform better when the data has a mean of zero and a standard deviation close to one. We specify the <code class="docutils literal notranslate"><span class="pre">mean</span></code> and <code class="docutils literal notranslate"><span class="pre">std</span></code> values for normalisation, tailored to our dataset.</p></li>
</ol>
<p>Transformations are applied sequentially using <code class="docutils literal notranslate"><span class="pre">torchvision.transforms.Compose</span></code>, which allows chaining multiple transformations together.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set mean and standard deviation for normalisation</span>
<span class="n">mean</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">std</span> <span class="o">=</span> <span class="mf">0.25</span>

<span class="c1"># Compose transformations</span>
<span class="n">transform</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>               <span class="c1"># Convert to tensor</span>
    <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">),</span>     <span class="c1"># Normalise with mean and std</span>
<span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="dataloader-managing-data-batches">
<h3>DataLoader: Managing Data Batches<a class="headerlink" href="#dataloader-managing-data-batches" title="Link to this heading">#</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> in PyTorch enables efficient batch processing, which is crucial for training and evaluation. Here are some important parameters for <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code>:</p>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">batch_size</span></code></strong>: Defines how many samples are processed in each batch. Processing in batches allows efficient use of GPU resources and is necessary for stochastic gradient descent (SGD).</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">num_workers</span></code></strong>: Specifies the number of CPU threads to load and preprocess the data before sending it to the GPU. Using multiple workers can speed up data loading, especially with larger datasets.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">shuffle</span></code></strong>: Randomly shuffles the data at each epoch. This is usually set to <code class="docutils literal notranslate"><span class="pre">True</span></code> during training to prevent the model from learning the order of the data.</p></li>
</ul>
<blockquote>
<div><p><strong>Note</strong>: <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> and <code class="docutils literal notranslate"><span class="pre">shuffle</span></code> settings can vary between training and testing. For example, we may set a larger <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> and avoid shuffling during testing since we do not need to update model weights.</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Instantiate dataset for training</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">ShapeDataset</span><span class="p">(</span><span class="n">train_imgs</span><span class="p">,</span> <span class="n">train_gts</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>

<span class="c1"># Set batch size</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">8</span>

<span class="c1"># Create DataLoader for training</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>

<span class="c1"># Instantiate dataset for validation</span>
<span class="n">val_dataset</span> <span class="o">=</span> <span class="n">ShapeDataset</span><span class="p">(</span><span class="n">test_imgs</span><span class="p">,</span> <span class="n">test_gts</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>

<span class="c1"># Create DataLoader for validation</span>
<span class="n">val_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">val_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="model">
<h2>2. Model<a class="headerlink" href="#model" title="Link to this heading">#</a></h2>
<p>With our images generated and PyTorch dataloaders ready, we can now move on to building our neural network model.</p>
<p>Since our task is relatively straightforward, we don’t need a highly complex model. In this example, we define a simple convolutional neural network (CNN) that will perform well on basic image classification tasks. Our model will inherit from <code class="docutils literal notranslate"><span class="pre">torch.nn.Module</span></code>, a base class in PyTorch used for creating neural network models. Any model that inherits from this class must implement at least a <code class="docutils literal notranslate"><span class="pre">forward</span></code> function, which defines how data will pass through the network layers.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">forward</span></code> function is automatically called whenever we pass data through the network. Here, it receives a batch of images, but it could take multiple inputs if needed, such as:</p>
<ul class="simple">
<li><p>Image pairs to check if they are similar</p></li>
<li><p>Triple images to identify the one that differs from the others</p></li>
</ul>
<section id="architecture">
<h3>Architecture<a class="headerlink" href="#architecture" title="Link to this heading">#</a></h3>
<p>In the <code class="docutils literal notranslate"><span class="pre">__init__</span></code> function, we set up our model’s architecture. This example (<code class="docutils literal notranslate"><span class="pre">SimpleNet</span></code>) consists of three main components:</p>
<ol class="arabic simple">
<li><p><strong>Feature Processing</strong> (<code class="docutils literal notranslate"><span class="pre">self.features</span></code>): This part is made up of three convolutional blocks. Each block includes:</p>
<ul class="simple">
<li><p><strong>Convolutional Layer</strong>: Extracts features by applying filters to the input images.</p></li>
<li><p><strong>Batch Normalisation</strong>: Stabilises training by normalising activations.</p></li>
<li><p><strong>ReLU Activation</strong>: Introduces non-linearity, helping the model to learn complex patterns.</p></li>
<li><p><strong>Max Pooling</strong>: Reduces the spatial dimensions (height and width), keeping the most important features.</p></li>
</ul>
</li>
<li><p><strong>Global Average Pooling</strong> (<code class="docutils literal notranslate"><span class="pre">self.avgpool</span></code>): This layer pools the features across the entire spatial resolution, producing a summary of each feature map.</p></li>
<li><p><strong>Classifier</strong> (<code class="docutils literal notranslate"><span class="pre">self.classifier</span></code>): This fully connected (linear) layer maps the extracted features to the number of classes, providing the final predictions.</p></li>
</ol>
<p>Let’s dive into the code to see how this structure is implemented.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the Simple CNN Model</span>
<span class="k">class</span><span class="w"> </span><span class="nc">SimpleNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialises the layers of the network.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            num_classes (int): Number of output classes for classification.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        
        <span class="c1"># Feature extraction layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>  <span class="c1"># Input channels=3 (RGB), Output channels=16</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">16</span><span class="p">),</span>                                    <span class="c1"># Batch normalisation for 16 channels</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>                                 <span class="c1"># Activation function</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>                 <span class="c1"># Max pooling with 3x3 filter and stride of 2</span>

            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="c1"># Increase channels to 32</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">32</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>

            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="c1"># Further increase channels to 64</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">64</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="p">)</span>
        
        <span class="c1"># Global average pooling to reduce spatial dimensions to 1x1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">avgpool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        
        <span class="c1"># Classification layer (fully connected layer)</span>
        <span class="c1"># Input size is 64, as it matches the output channels of the last convolution layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1</span> <span class="o">*</span> <span class="mi">1</span> <span class="o">*</span> <span class="mi">64</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Defines the forward pass through the network.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            x (torch.Tensor): Input batch of images.</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: Output predictions for each input image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Pass the input through the feature extraction layers</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="c1"># Apply global average pooling</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">avgpool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="c1"># Flatten the output from the feature extraction to 1D (required by classifier)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        
        <span class="c1"># Pass through the classification layer to get the final output</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
<p>Explanation of Key Components:</p>
<ol class="arabic simple">
<li><p><strong>Feature Extraction Layers (<code class="docutils literal notranslate"><span class="pre">self.features</span></code>)</strong>: Each convolutional block in <code class="docutils literal notranslate"><span class="pre">self.features</span></code> extracts increasingly complex patterns from the images. The convolutional layers increase the depth (number of channels) of the feature maps from 3 (RGB channels) to 16, 32, and finally 64. Batch normalisation stabilises the activations, and ReLU introduces non-linearities that help the model learn complex features.</p></li>
<li><p><strong>Global Average Pooling (<code class="docutils literal notranslate"><span class="pre">self.avgpool</span></code>)</strong>: By reducing the feature maps to a single value per channel, global average pooling summarises the features and allows the classifier to operate on a fixed-size input, regardless of the image dimensions.</p></li>
<li><p><strong>Fully Connected Layer (<code class="docutils literal notranslate"><span class="pre">self.classifier</span></code>)</strong>: This layer maps the processed features to the number of classes, producing the final predictions. Here, <code class="docutils literal notranslate"><span class="pre">num_classes</span></code> represents the number of categories we want to classify.</p></li>
</ol>
</section>
<section id="network">
<h3>Network<a class="headerlink" href="#network" title="Link to this heading">#</a></h3>
<p>Now that we’ve defined the model architecture, we’ll create an instance of <code class="docutils literal notranslate"><span class="pre">SimpleNet</span></code>, specifying the number of output classes. We then move the model to the GPU for faster computation if available, and print out the model’s structure to verify.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Instantiate the model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SimpleNet</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">labels_map</span><span class="p">))</span>

<span class="c1"># Move the model to the GPU if available</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Print the model architecture to review</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>SimpleNet(
  (features): Sequential(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU(inplace=True)
    (7): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU(inplace=True)
    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (classifier): Linear(in_features=64, out_features=3, bias=True)
)
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="training-and-testing-routines">
<h2>3. Training and Testing Routines<a class="headerlink" href="#training-and-testing-routines" title="Link to this heading">#</a></h2>
<p>Now that we’ve prepared our dataset and built our model, it’s time to start training and evaluating our neural network. This section explains each component of the training process, including optimisation, loss calculation, and accuracy evaluation.</p>
<section id="optimiser">
<h3>Optimiser<a class="headerlink" href="#optimiser" title="Link to this heading">#</a></h3>
<p>The optimiser is responsible for updating the model’s parameters to minimise the loss during training. When defining an optimiser, we choose which parameters to optimise, the optimisation algorithm, and a key parameter called the <strong>learning rate</strong>. The learning rate controls how much to adjust the model’s parameters with each step.</p>
<p>In our case, we use <strong>Stochastic Gradient Descent (SGD)</strong> with parameters for <code class="docutils literal notranslate"><span class="pre">momentum</span></code>, <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code>, and <code class="docutils literal notranslate"><span class="pre">weight_decay</span></code>. Each plays an important role:</p>
<ul class="simple">
<li><p><strong>Learning Rate</strong>: Controls the step size in each update; too large a value might skip over optimal values, and too small a value could result in slow learning.</p></li>
<li><p><strong>Momentum</strong>: Helps accelerate gradients to optimise faster and avoid oscillations.</p></li>
<li><p><strong>Weight Decay</strong>: Adds a penalty to large weights to prevent overfitting.</p></li>
</ul>
<p><img alt="learning-rate" src="https://www.jeremyjordan.me/content/images/2018/02/Screen-Shot-2018-02-24-at-11.47.09-AM.png" /></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define optimiser and criterion</span>
<span class="n">params_to_optimise</span> <span class="o">=</span> <span class="p">[{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()]}]</span>
<span class="n">momentum</span> <span class="o">=</span> <span class="mf">0.9</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">weight_decay</span> <span class="o">=</span> <span class="mf">1e-4</span>

<span class="c1"># Initialising the SGD optimiser with specified parameters</span>
<span class="n">optimiser</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span>
    <span class="n">params</span><span class="o">=</span><span class="n">params_to_optimise</span><span class="p">,</span>
    <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
    <span class="n">momentum</span><span class="o">=</span><span class="n">momentum</span><span class="p">,</span>
    <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="loss-function">
<h3>Loss Function<a class="headerlink" href="#loss-function" title="Link to this heading">#</a></h3>
<p>The <strong>loss function</strong> quantifies how well the model’s predictions match the ground truth. In this example, we use <strong>categorical cross-entropy</strong> (<code class="docutils literal notranslate"><span class="pre">nn.CrossEntropyLoss</span></code>) as our loss function, which is well-suited for classification tasks where the goal is to correctly categorise inputs into discrete classes (like recognising different shapes).</p>
<p>We can consider the learning paradigm in this example to be <strong>semi-supervised</strong>. The ground-truth labels for our shapes were not manually annotated by humans. Instead, we automatically generated these labels using mathematical equations to define the geometrical shapes. This approach allowed us to skip the laborious process of manually labelling each image, providing labelled data in a more efficient way.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Initialise the loss function (categorical cross-entropy)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="training-testing-utility-functions">
<h3>Training-testing Utility Functions<a class="headerlink" href="#training-testing-utility-functions" title="Link to this heading">#</a></h3>
<p>To evaluate model performance, we use an <code class="docutils literal notranslate"><span class="pre">accuracy</span></code> function that calculates how many predictions match the ground truth.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">accuracy</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">topk</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,)):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the accuracy over the top k predictions.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        output (torch.Tensor): Model predictions.</span>
<span class="sd">        target (torch.Tensor): Ground truth labels.</span>
<span class="sd">        topk (tuple): Top k values to compute accuracy for.</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">        List of accuracies for specified top k values.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">maxk</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">topk</span><span class="p">)</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Get top k predictions</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">pred</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">maxk</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>
        <span class="n">correct</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">pred</span><span class="p">))</span>

        <span class="n">res</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">topk</span><span class="p">:</span>
            <span class="n">correct_k</span> <span class="o">=</span> <span class="n">correct</span><span class="p">[:</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">res</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">correct_k</span><span class="o">.</span><span class="n">mul_</span><span class="p">(</span><span class="mf">100.0</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">res</span>
</pre></div>
</div>
</div>
</div>
<p>To train and evaluate our model, we define a utility function called <code class="docutils literal notranslate"><span class="pre">epoch_loop</span></code>, which performs the operations required in each epoch. An <strong>epoch</strong> refers to one complete pass through the entire dataset—essentially, processing all samples in the dataset once.</p>
<p>Since much of the code for training and testing is similar, it’s efficient to combine both procedures into a single function. The parts that differ for training and testing can be separated within the function using conditional statements. For example, during training, we need to perform additional steps to update the model’s parameters:</p>
<ol class="arabic simple">
<li><p><strong>Compute the Gradient</strong>: We reset the gradients with <code class="docutils literal notranslate"><span class="pre">optimizer.zero_grad()</span></code>, ensuring that previous gradients do not interfere with the current update.</p></li>
<li><p><strong>Backpropagate the Loss</strong>: We calculate the gradients with <code class="docutils literal notranslate"><span class="pre">loss.backward()</span></code>, which backpropagates the loss to update each parameter in the network.</p></li>
<li><p><strong>Optimise the Weights</strong>: Finally, <code class="docutils literal notranslate"><span class="pre">optimizer.step()</span></code> adjusts the weights based on the computed gradients, helping the model learn from the errors.</p></li>
</ol>
<p><font color='red'><strong>Important</strong></font>: When evaluating (or testing) a model, it’s essential to call the <code class="docutils literal notranslate"><span class="pre">.eval()</span></code> method. This prevents certain layers (like dropout or batch normalisation) from updating, ensuring a consistent evaluation.</p>
<p><font color='red'><strong>Important</strong></font>: Also, use <code class="docutils literal notranslate"><span class="pre">torch.set_grad_enabled()</span></code> to specify whether gradients should be calculated (<code class="docutils literal notranslate"><span class="pre">True</span></code> during training and <code class="docutils literal notranslate"><span class="pre">False</span></code> during testing).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">epoch_loop</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">db_loader</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimiser</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Run a single epoch for training or testing.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        model (torch.nn.Module): The model to train/test.</span>
<span class="sd">        db_loader (DataLoader): Data loader for training or testing data.</span>
<span class="sd">        criterion (Loss Function): Loss function for computing the error.</span>
<span class="sd">        optimiser (torch.optim.Optimizer): Optimiser for training; if None, evaluation mode is assumed.</span>
<span class="sd">        </span>
<span class="sd">    Returns:</span>
<span class="sd">        accuracies (list): List of accuracies for each batch.</span>
<span class="sd">        losses (list): List of losses for each batch.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Determine whether in training mode</span>
    <span class="n">is_train</span> <span class="o">=</span> <span class="n">optimiser</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span> <span class="k">if</span> <span class="n">is_train</span> <span class="k">else</span> <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    
    <span class="n">accuracies</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="c1"># Disable gradient computation for evaluation</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">set_grad_enabled</span><span class="p">(</span><span class="n">is_train</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">batch_ind</span><span class="p">,</span> <span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">db_loader</span><span class="p">):</span>
            <span class="c1"># Move images and targets to device (GPU or CPU)</span>
            <span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">target</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            
            <span class="c1"># Forward pass: compute output and loss</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
            <span class="n">losses</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">))])</span>

            <span class="c1"># Compute accuracy</span>
            <span class="n">acc</span> <span class="o">=</span> <span class="n">accuracy</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">accuracies</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">acc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">))])</span>
            
            <span class="c1"># Backward pass and optimisation step for training</span>
            <span class="k">if</span> <span class="n">is_train</span><span class="p">:</span>
                <span class="n">optimiser</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>   <span class="c1"># Reset gradients</span>
                <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>         <span class="c1"># Backpropagate loss</span>
                <span class="n">optimiser</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>        <span class="c1"># Update parameters</span>
    
    <span class="k">return</span> <span class="n">accuracies</span><span class="p">,</span> <span class="n">losses</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="actual-learning">
<h2>4. Actual Learning<a class="headerlink" href="#actual-learning" title="Link to this heading">#</a></h2>
<p>With all components set up (data, model, loss, and optimiser), we can start the training and testing loop. In this example, we train the model for 10 epochs, meaning the model will go through all data points 10 times.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the number of epochs for training</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">initial_epoch</span> <span class="o">=</span> <span class="mi">0</span>

<span class="c1"># Logs for tracking accuracy and loss over time</span>
<span class="n">train_logs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;acc&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="p">[]}</span>
<span class="n">val_logs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;acc&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="p">[]}</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">initial_epoch</span><span class="p">,</span> <span class="n">epochs</span><span class="p">):</span>
    <span class="c1"># Run a training epoch</span>
    <span class="n">train_log</span> <span class="o">=</span> <span class="n">epoch_loop</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimiser</span><span class="p">)</span>
    
    <span class="c1"># Run a validation epoch (no optimiser, so the model is in evaluation mode)</span>
    <span class="n">val_log</span> <span class="o">=</span> <span class="n">epoch_loop</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimiser</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    
    <span class="c1"># Print training and validation results for this epoch</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[Epoch </span><span class="si">%02d</span><span class="s1">] Train loss=</span><span class="si">%.4f</span><span class="s1">, acc=</span><span class="si">%.2f</span><span class="s1">  |  Test loss=</span><span class="si">%.4f</span><span class="s1">, acc=</span><span class="si">%.2f</span><span class="s1">&#39;</span> <span class="o">%</span> 
          <span class="p">(</span>
              <span class="n">epoch</span><span class="p">,</span> 
              <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_log</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_log</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
              <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">val_log</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">val_log</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
          <span class="p">))</span>
    
    <span class="c1"># Log the results for plotting later</span>
    <span class="n">train_logs</span><span class="p">[</span><span class="s1">&#39;acc&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_log</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">train_logs</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_log</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">val_logs</span><span class="p">[</span><span class="s1">&#39;acc&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">val_log</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">val_logs</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">val_log</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[Epoch 00] Train loss=1.1124, acc=40.90  |  Test loss=1.2221, acc=42.00
[Epoch 01] Train loss=1.1025, acc=41.10  |  Test loss=1.2636, acc=38.00
[Epoch 02] Train loss=1.0391, acc=46.90  |  Test loss=1.0798, acc=48.00
[Epoch 03] Train loss=0.9091, acc=54.70  |  Test loss=0.8103, acc=59.00
[Epoch 04] Train loss=0.8988, acc=53.10  |  Test loss=1.0602, acc=47.00
[Epoch 05] Train loss=0.7880, acc=58.10  |  Test loss=0.6772, acc=66.00
[Epoch 06] Train loss=0.8650, acc=56.50  |  Test loss=1.1552, acc=46.00
[Epoch 07] Train loss=0.7641, acc=61.60  |  Test loss=0.6309, acc=64.00
[Epoch 08] Train loss=0.6566, acc=62.60  |  Test loss=0.6128, acc=61.00
[Epoch 09] Train loss=0.6392, acc=62.90  |  Test loss=0.9192, acc=49.00
</pre></div>
</div>
</div>
</div>
</section>
<section id="reporting-results">
<h2>5. Reporting Results<a class="headerlink" href="#reporting-results" title="Link to this heading">#</a></h2>
<p>Finally, we’ll plot the accuracy and loss over the training epochs to evaluate the model’s performance. These plots can reveal if the model is improving over time or if adjustments are needed to hyperparameters.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot accuracy and loss over epochs</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="c1"># Plot accuracy</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_logs</span><span class="p">[</span><span class="s1">&#39;acc&#39;</span><span class="p">],</span> <span class="s1">&#39;-x&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">val_logs</span><span class="p">[</span><span class="s1">&#39;acc&#39;</span><span class="p">],</span> <span class="s1">&#39;-o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Model Accuracy&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch Number&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="c1"># Plot loss</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_logs</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="s1">&#39;-x&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">val_logs</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="s1">&#39;-o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Model Loss&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch Number&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/06bebb09584084b90652f5ec47819966dcfdd5374e20282954cc6dae2eb37e0c.png" src="../_images/06bebb09584084b90652f5ec47819966dcfdd5374e20282954cc6dae2eb37e0c.png" />
</div>
</div>
</section>
<section id="exercises">
<h2>Exercises<a class="headerlink" href="#exercises" title="Link to this heading">#</a></h2>
<p>These exercises are designed to help you extend and test the concepts covered in this chapter. Each exercise challenges you to apply your knowledge to adjust the data handling, background properties, and shape complexity of the dataset.</p>
<section id="implementing-a-dataloader-to-load-images-from-disk">
<h3>1. Implementing a Dataloader to Load Images from Disk<a class="headerlink" href="#implementing-a-dataloader-to-load-images-from-disk" title="Link to this heading">#</a></h3>
<p>As discussed, we generally cannot load all images into memory due to limitations, especially when working with large datasets.</p>
<p><strong>Objective</strong>: Modify the code to load images on the fly from a specified directory structure.</p>
<ol class="arabic simple">
<li><p>Download this <a class="reference external" href="https://www.dropbox.com/s/rltbecab0zx1zep/shape_set.zip?dl=0">zip file</a> and extract it. The directory contains:</p>
<ul class="simple">
<li><p>Two subfolders: <code class="docutils literal notranslate"><span class="pre">train</span></code> and <code class="docutils literal notranslate"><span class="pre">test</span></code>, holding the training and test images, respectively.</p></li>
<li><p>Two CSV files with ground truth labels for the images in <code class="docutils literal notranslate"><span class="pre">train</span></code> and <code class="docutils literal notranslate"><span class="pre">test</span></code>.</p></li>
</ul>
</li>
<li><p>Update the dataloader to accept a directory path as an argument.</p></li>
<li><p>Instead of loading all images at once, adjust the <code class="docutils literal notranslate"><span class="pre">__getitem__</span></code> function in your <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> class to load each image directly from disk. This function should read each image and return it with its associated label.</p></li>
</ol>
<p>This approach enables efficient memory usage and prepares you to work with real-world datasets that cannot fit into memory.</p>
</section>
<section id="exploring-the-effect-of-background-colour-in-training-and-testing">
<h3>2. Exploring the Effect of Background Colour in Training and Testing<a class="headerlink" href="#exploring-the-effect-of-background-colour-in-training-and-testing" title="Link to this heading">#</a></h3>
<p>In this exercise, you will experiment with the background colour of images in the training and test sets. By changing background properties, you can investigate how well the model generalises under different conditions.</p>
<ol class="arabic simple">
<li><p><strong>Achromatic vs Colourful Backgrounds</strong>:</p>
<ul class="simple">
<li><p>Update the dataloader to accept an argument specifying the type of background (achromatic or colourful).</p></li>
<li><p>For the training set, use only <strong>achromatic (greyscale) backgrounds</strong>.</p></li>
<li><p>For the test set, use <strong>colourful backgrounds</strong>.</p></li>
<li><p>Train the model and observe if it can generalise to images with colourful backgrounds in the test set.</p></li>
</ul>
</li>
<li><p><strong>Swap Background Colours</strong>:</p>
<ul class="simple">
<li><p>Switch the backgrounds so that the training set has <strong>colourful backgrounds</strong> and the test set has <strong>greyscale backgrounds</strong>.</p></li>
<li><p>Observe how this impacts the model’s performance.</p></li>
</ul>
</li>
<li><p><strong>Experiments with Foreground Colours</strong>:</p>
<ul class="simple">
<li><p>Conduct similar experiments by modifying the colours of the foreground shapes instead of the background.</p></li>
</ul>
</li>
</ol>
<p><strong>Bonus</strong>: If the model struggles to learn the task with these manipulations, experiment with additional training epochs, or modify the network architecture to improve test accuracy. This challenge will help you understand how to tune model complexity and training duration for more complex tasks.</p>
</section>
<section id="adding-new-geometrical-shapes-to-the-dataset">
<h3>3. Adding New Geometrical Shapes to the Dataset<a class="headerlink" href="#adding-new-geometrical-shapes-to-the-dataset" title="Link to this heading">#</a></h3>
<p>Our current dataset contains only three types of geometrical shapes. This exercise involves expanding the dataset by adding one or more new shapes, such as squares or triangles.</p>
<ol class="arabic simple">
<li><p>Modify the data generation function to add at least one new shape.</p></li>
<li><p>Visualise a few examples of your updated dataset to confirm the new shapes are included.</p></li>
<li><p>Update the network and training code to accommodate the expanded set of classes, then train the model with the new dataset.</p></li>
</ol>
<p>By extending the dataset, you’ll learn how to adapt your data generation and model design to recognise an increased number of classes. This is useful practice for scaling models to handle more complex data.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="dropout.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">1.6. Dropout</p>
      </div>
    </a>
    <a class="right-next"
       href="optimisation_learning.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">3. Optimisation and Learning</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preparation">0. Preparation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#required-packages">Required Packages</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset">1. Dataset</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-utility-functions">Dataset Utility Functions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-and-testing-sets">Training and Testing Sets</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-visualisation">Dataset Visualisation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch-data-pipeline">PyTorch Data Pipeline</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-transformations">Data Transformations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dataloader-managing-data-batches">DataLoader: Managing Data Batches</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model">2. Model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#architecture">Architecture</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#network">Network</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-and-testing-routines">3. Training and Testing Routines</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optimiser">Optimiser</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#loss-function">Loss Function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-testing-utility-functions">Training-testing Utility Functions</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#actual-learning">4. Actual Learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reporting-results">5. Reporting Results</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">Exercises</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implementing-a-dataloader-to-load-images-from-disk">1. Implementing a Dataloader to Load Images from Disk</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exploring-the-effect-of-background-colour-in-training-and-testing">2. Exploring the Effect of Background Colour in Training and Testing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#adding-new-geometrical-shapes-to-the-dataset">3. Adding New Geometrical Shapes to the Dataset</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Arash Akbarinia
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>